{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a39a70f8",
   "metadata": {},
   "source": [
    "# Exercice 01 - Introduction au Big Data\n",
    "\n",
    "## Objectifs\n",
    "- Comprendre ce qu'est le Big Data\n",
    "- Découvrir les 3V (Volume, Vélocité, Variété)\n",
    "- Comprendre pourquoi les outils classiques ne suffisent plus\n",
    "- Découvrir les outils Big Data modernes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73557733",
   "metadata": {},
   "source": [
    "## 1️⃣ Qu'est-ce que le Big Data ?\n",
    "\n",
    "Le **Big Data** désigne des ensembles de données tellement volumineux et complexes qu'ils ne peuvent pas être traités par les outils traditionnels.\n",
    "\n",
    "### Exemples concrets de Big Data\n",
    "\n",
    "| Source | Volume par jour |\n",
    "|--------|----------------|\n",
    "| Facebook | 4 pétaoctets |\n",
    "| Twitter | 500 millions de tweets |\n",
    "| Netflix | 1 milliard d'heures de streaming |\n",
    "| Capteurs IoT | Des milliards de mesures |\n",
    "\n",
    "### Pour visualiser\n",
    "\n",
    "```\n",
    "1 Ko (Kilo-octet)    = Un SMS\n",
    "1 Mo (Méga-octet)    = Une photo\n",
    "1 Go (Giga-octet)    = Un film HD\n",
    "1 To (Téra-octet)    = 1000 films HD\n",
    "1 Po (Péta-octet)    = 1 000 000 films HD  ← Facebook génère 4x ça par jour !\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93a1a66",
   "metadata": {},
   "source": [
    "## 2️⃣ Les 3V du Big Data\n",
    "\n",
    "```\n",
    "\n",
    "                   BIG DATA               \n",
    "                                                 \n",
    "                        ┌─────────┐                   \n",
    "                        │ VOLUME  │ ← Quantité        \n",
    "                        └────┬────┘   massive         \n",
    "                             │                        \n",
    "          ┌──────────────────┴─────────┐              \n",
    "          │                            │              \n",
    "    ┌─────▼─────┐              ┌───────▼───────┐      \n",
    "    │ VÉLOCITÉ  │              │   VARIÉTÉ     │      \n",
    "    │           │              │               │     \n",
    "    │  Données  │              │ Données de    │      \n",
    "    │  en temps │              │ types variés  │      \n",
    "    │  réel     │              │ (texte, image,│      \n",
    "    │           │              │  vidéo, JSON) │      \n",
    "    └───────────┘              └───────────────┘      \n",
    "                 \n",
    "```\n",
    "\n",
    "### Volume\n",
    "- Téraoctets, Pétaoctets de données\n",
    "- Impossible de charger en mémoire sur un seul ordinateur\n",
    "\n",
    "### Vélocité\n",
    "- Données générées en continu\n",
    "- Besoin de traitement en temps réel\n",
    "\n",
    "### Variété\n",
    "- Données structurées (tables SQL)\n",
    "- Données semi-structurées (JSON, XML)\n",
    "- Données non structurées (texte, images, vidéos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb1e5e7",
   "metadata": {},
   "source": [
    "## 3️⃣ Pourquoi Excel et SQL ne suffisent plus ?\n",
    "\n",
    "### Limites d'Excel\n",
    "- Maximum **1 048 576 lignes** par feuille\n",
    "- Ralentit fortement au-delà de 100 000 lignes\n",
    "- Un seul processeur utilisé\n",
    "\n",
    "### Limites d'une base SQL classique\n",
    "- Fonctionne sur **un seul serveur**\n",
    "- Coûteux de mettre à l'échelle (scaling vertical)\n",
    "- Pas conçu pour les données non structurées\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────┐\n",
    "│                    APPROCHE CLASSIQUE                          │\n",
    "│                                                                │\n",
    "│   ┌──────────┐                    ┌──────────────────────┐     │\n",
    "│   │ Données  │ ──────────────────▶│  1 SERVEUR PUISSANT  │     │\n",
    "│   │ (petit)  │                    │  (limité en RAM/CPU) │     │\n",
    "│   └──────────┘                    └──────────────────────┘     │\n",
    "│                                                                │\n",
    "│   ❌ Ne peut pas traiter des téraoctets                        │\n",
    "└────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌───────────────────────────────────────────────────────────────┐\n",
    "│                    APPROCHE BIG DATA                          │\n",
    "│                                                               │\n",
    "│   ┌──────────┐     ┌──────────┐  ┌──────────┐  ┌──────────┐   │\n",
    "│   │ Données  │ ──▶│ Serveur 1│  │ Serveur 2│  │ Serveur 3│   │\n",
    "│   │ (énorme) │     └──────────┘  └──────────┘  └──────────┘   │\n",
    "│   └──────────┘           │             │             │        │\n",
    "│                          └─────────────┴─────────────┘        │\n",
    "│                                   │                           │\n",
    "│                                   ▼                           │\n",
    "│                          ┌─────────────────┐                  │\n",
    "│                          │   RÉSULTAT      │                  │\n",
    "│                          └─────────────────┘                  │\n",
    "│                                                               │\n",
    "│   ✅ Traitement distribué = Scalabilité horizontale           │\n",
    "└───────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78122841",
   "metadata": {},
   "source": [
    "## 4️⃣ Les outils Big Data modernes\n",
    "\n",
    "### Apache Spark \n",
    "- Moteur de traitement distribué\n",
    "- Traite les données **en mémoire** (très rapide)\n",
    "- Supporte SQL, Machine Learning, Streaming\n",
    "- **C'est ce que nous allons utiliser !**\n",
    "\n",
    "### Apache Kafka\n",
    "- Système de messagerie distribué\n",
    "- Gère les flux de données en temps réel\n",
    "- **Nous le verrons plus tard**\n",
    "\n",
    "### MinIO (S3)\n",
    "- Stockage objet compatible S3\n",
    "- Stocke des fichiers de toute taille\n",
    "- **Notre Data Lake !**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560d1605",
   "metadata": {},
   "source": [
    "## 5️⃣ Démonstration : Limites de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91729afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Petit DataFrame (1 000 lignes) :\n",
      "   id  valeur\n",
      "0   0       0\n",
      "1   1       1\n",
      "2   2       2\n",
      "3   3       3\n",
      "4   4       4\n",
      "\n",
      "Taille en mémoire : 15.75 Ko\n"
     ]
    }
   ],
   "source": [
    "# Importons Pandas\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Créons un petit DataFrame\n",
    "petit_df = pd.DataFrame({\n",
    "    'id': range(1000),\n",
    "    'valeur': range(1000)\n",
    "})\n",
    "\n",
    "print(\"Petit DataFrame (1 000 lignes) :\")\n",
    "print(petit_df.head())\n",
    "print(f\"\\nTaille en mémoire : {petit_df.memory_usage(deep=True).sum() / 1024:.2f} Ko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcfa1a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame créé en 0.07 secondes\n",
      "Nombre de lignes : 1,000,000\n",
      "Taille en mémoire : 70.57 Mo\n"
     ]
    }
   ],
   "source": [
    "# Créons un DataFrame plus grand\n",
    "import numpy as np\n",
    "\n",
    "# 1 million de lignes\n",
    "nb_lignes = 1_000_000\n",
    "\n",
    "debut = time.time()\n",
    "grand_df = pd.DataFrame({\n",
    "    'id': range(nb_lignes),\n",
    "    'valeur_a': np.random.rand(nb_lignes),\n",
    "    'valeur_b': np.random.rand(nb_lignes),\n",
    "    'categorie': np.random.choice(['A', 'B', 'C', 'D'], nb_lignes)\n",
    "})\n",
    "fin = time.time()\n",
    "\n",
    "print(f\"DataFrame créé en {fin - debut:.2f} secondes\")\n",
    "print(f\"Nombre de lignes : {len(grand_df):,}\")\n",
    "print(f\"Taille en mémoire : {grand_df.memory_usage(deep=True).sum() / (1024*1024):.2f} Mo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ea9fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agrégation terminée en 0.0567 secondes\n",
      "\n",
      "Résultat :\n",
      "           valeur_a       valeur_b\n",
      "categorie                         \n",
      "A          0.500106  124880.196271\n",
      "B          0.499888  124738.650380\n",
      "C          0.499616  125170.271992\n",
      "D          0.498445  125304.668046\n"
     ]
    }
   ],
   "source": [
    "# Agrégation sur le grand DataFrame\n",
    "debut = time.time()\n",
    "resultat = grand_df.groupby('categorie').agg({\n",
    "    'valeur_a': 'mean',\n",
    "    'valeur_b': 'sum'\n",
    "})\n",
    "fin = time.time()\n",
    "\n",
    "print(f\"Agrégation terminée en {fin - debut:.4f} secondes\")\n",
    "print(\"\\nRésultat :\")\n",
    "print(resultat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae50207",
   "metadata": {},
   "source": [
    "### Ce qu'il faut retenir\n",
    "\n",
    "Avec **1 million de lignes**, Pandas fonctionne encore bien sur un ordinateur moderne.\n",
    "\n",
    "Mais imaginez :\n",
    "- **1 milliard de lignes** → 1 000x plus\n",
    "- **100 colonnes** au lieu de 4\n",
    "- **En continu**, toutes les secondes\n",
    "\n",
    "➡️ C'est là que **Spark** devient indispensable !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8c489b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice\n",
    "\n",
    "**Objectif** : Comprendre les limites de Pandas\n",
    "\n",
    "**Consigne** :\n",
    "1. Créez un DataFrame Pandas avec **5 millions** de lignes\n",
    "2. Mesurez le temps de création\n",
    "3. Mesurez la taille mémoire\n",
    "4. Faites une agrégation et mesurez le temps\n",
    "\n",
    "**Questions** :\n",
    "- Combien de mémoire est utilisée ?\n",
    "- Combien de temps prend l'agrégation ?\n",
    "- Que se passerait-il avec 1 milliard de lignes ?\n",
    "\n",
    "À vous de jouer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba5935fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps de création : 0.36 secondes\n",
      "Taille mémoire : 354.05 Mo\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# TODO: Créez un DataFrame avec 5 millions de lignes\n",
    "nb_lignes = 5_000_000  # 5 millions\n",
    "\n",
    "debut = time.time()\n",
    "\n",
    "# Votre code ici pour créer le DataFrame\n",
    "# Conseil : utilisez le même modèle que l'exemple précédent\n",
    "df = pd.DataFrame({\n",
    "    'id': range(nb_lignes),\n",
    "    'poids': np.random.rand(nb_lignes),\n",
    "    'taille': np.random.rand(nb_lignes),\n",
    "    'groupe_sanguin': np.random.choice(['A', 'B', 'AB', 'O'], nb_lignes)\n",
    "})\n",
    "\n",
    "fin = time.time()\n",
    "\n",
    "print(f\"Temps de création : {fin - debut:.2f} secondes\")\n",
    "print(f\"Taille mémoire : {df.memory_usage(deep=True).sum() / (1024*1024):.2f} Mo\")  # Calculez la taille"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ede051",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ Résumé\n",
    "\n",
    "Dans ce notebook, vous avez appris :\n",
    "\n",
    "- Le **Big Data** = données trop volumineuses pour les outils classiques\n",
    "- Les **3V** : Volume, Vélocité, Variété\n",
    "- Pourquoi **Excel et SQL classique** ne suffisent plus\n",
    "- L'approche **distribuée** du Big Data\n",
    "- Les outils modernes : **Spark**, **Kafka**, **MinIO**\n",
    "\n",
    "### Prochaine étape\n",
    "Dans le prochain notebook, nous découvrirons ce qu'est un **Data Lake** et l'architecture **Bronze / Silver / Gold**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95b97e5-18ed-49c0-a041-02473956d3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
