{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdfcd57d",
   "metadata": {},
   "source": [
    "# Exercice 09 - Nettoyage des donnees (Silver)\n",
    "\n",
    "## Objectifs\n",
    "- Comprendre la couche Silver du Data Lake\n",
    "- Gerer les valeurs nulles\n",
    "- Supprimer les doublons\n",
    "- Standardiser les formats de donnees\n",
    "- Valider la qualite des donnees\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ab372",
   "metadata": {},
   "source": [
    "## 1. La couche Silver\n",
    "\n",
    "```\n",
    "+------------------+     +------------------+     +------------------+\n",
    "|      BRONZE      |     |      SILVER      |     |       GOLD       |\n",
    "+------------------+     +------------------+     +------------------+\n",
    "|                  |     |                  |     |                  |\n",
    "| Donnees brutes   | --> | Donnees propres  | --> | Donnees business |\n",
    "| Non validees     |     | Validees         |     | Agregatees       |\n",
    "| Avec doublons    |     | Sans doublons    |     | Optimisees       |\n",
    "| Formats varies   |     | Formats standards|     | Pretes a l'usage |\n",
    "|                  |     |                  |     |                  |\n",
    "+------------------+     +------------------+     +------------------+\n",
    "\n",
    "Nettoyages Silver :\n",
    "- Suppression des doublons\n",
    "- Gestion des valeurs nulles\n",
    "- Standardisation des formats\n",
    "- Validation des types\n",
    "- Correction des erreurs evidentes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f53a0",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2736edda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark prêt - Date : 2026-01-15\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType, DateType\n",
    "from datetime import datetime\n",
    "\n",
    "# Créer la SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Nettoyage Silver\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.6.0,org.apache.hadoop:hadoop-aws:3.4.1,com.amazonaws:aws-java-sdk-bundle:1.12.262\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin123\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "date_traitement = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "print(f\"Spark prêt - Date : {date_traitement}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4233528",
   "metadata": {},
   "source": [
    "## 3. Creer des donnees de test avec des problemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "386da2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donnees brutes (Bronze) :\n",
      "+---+-------+---------------+-------------+---+-------+\n",
      "|id |nom    |email          |ville        |age|salaire|\n",
      "+---+-------+---------------+-------------+---+-------+\n",
      "|1  |Alice  |alice@email.com|Paris        |25 |50000.0|\n",
      "|2  |Bob    |BOB@EMAIL.COM  |paris        |30 |60000.0|\n",
      "|3  |Charlie|NULL           |Lyon         |35 |NULL   |\n",
      "|4  |Diana  |diana@email.com|  Marseille  |-5 |70000.0|\n",
      "|1  |Alice  |alice@email.com|Paris        |25 |50000.0|\n",
      "|5  |Eve    |eve@email      |Toulouse     |28 |55000.0|\n",
      "|6  |Frank  |frank@email.com|             |40 |80000.0|\n",
      "|7  |Grace  |grace@email.com|Nice         |150|65000.0|\n",
      "+---+-------+---------------+-------------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Donnees avec des problemes courants\n",
    "data_problemes = [\n",
    "    (1, \"Alice\", \"alice@email.com\", \"Paris\", 25, 50000.0),\n",
    "    (2, \"Bob\", \"BOB@EMAIL.COM\", \"paris\", 30, 60000.0),      # Email en majuscules, ville minuscule\n",
    "    (3, \"Charlie\", None, \"Lyon\", 35, None),                  # Valeurs nulles\n",
    "    (4, \"Diana\", \"diana@email.com\", \"  Marseille  \", -5, 70000.0),  # Espaces, age negatif\n",
    "    (1, \"Alice\", \"alice@email.com\", \"Paris\", 25, 50000.0),   # Doublon\n",
    "    (5, \"Eve\", \"eve@email\", \"Toulouse\", 28, 55000.0),        # Email invalide\n",
    "    (6, \"Frank\", \"frank@email.com\", \"\", 40, 80000.0),        # Ville vide\n",
    "    (7, \"Grace\", \"grace@email.com\", \"Nice\", 150, 65000.0),   # Age impossible\n",
    "]\n",
    "\n",
    "colonnes = [\"id\", \"nom\", \"email\", \"ville\", \"age\", \"salaire\"]\n",
    "df_bronze = spark.createDataFrame(data_problemes, colonnes)\n",
    "\n",
    "print(\"Donnees brutes (Bronze) :\")\n",
    "df_bronze.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532aaab8",
   "metadata": {},
   "source": [
    "## 4. Supprimer les doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7effa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lignes avant : 8\n",
      "Lignes apres dropDuplicates() : 7\n",
      "Lignes apres dropDuplicates(['id']) : 7\n"
     ]
    }
   ],
   "source": [
    "# Compter avant\n",
    "print(f\"Lignes avant : {df_bronze.count()}\")\n",
    "\n",
    "# Supprimer les doublons exacts\n",
    "df_sans_doublons = df_bronze.dropDuplicates()\n",
    "print(f\"Lignes apres dropDuplicates() : {df_sans_doublons.count()}\")\n",
    "\n",
    "# Supprimer les doublons sur certaines colonnes\n",
    "df_sans_doublons_id = df_bronze.dropDuplicates([\"id\"])\n",
    "print(f\"Lignes apres dropDuplicates(['id']) : {df_sans_doublons_id.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eadf95c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---------------+-------------+---+-------+\n",
      "| id|    nom|          email|        ville|age|salaire|\n",
      "+---+-------+---------------+-------------+---+-------+\n",
      "|  1|  Alice|alice@email.com|        Paris| 25|50000.0|\n",
      "|  2|    Bob|  BOB@EMAIL.COM|        paris| 30|60000.0|\n",
      "|  4|  Diana|diana@email.com|  Marseille  | -5|70000.0|\n",
      "|  5|    Eve|      eve@email|     Toulouse| 28|55000.0|\n",
      "|  6|  Frank|frank@email.com|             | 40|80000.0|\n",
      "|  7|  Grace|grace@email.com|         Nice|150|65000.0|\n",
      "|  3|Charlie|           NULL|         Lyon| 35|   NULL|\n",
      "+---+-------+---------------+-------------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Continuer avec les donnees sans doublons\n",
    "df = df_sans_doublons\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2790d9db",
   "metadata": {},
   "source": [
    "## 5. Gerer les valeurs nulles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92660d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs nulles par colonne :\n",
      "  id: 0\n",
      "  nom: 0\n",
      "  email: 1\n",
      "  ville: 0\n",
      "  age: 0\n",
      "  salaire: 1\n"
     ]
    }
   ],
   "source": [
    "# Compter les valeurs nulles par colonne\n",
    "print(\"Valeurs nulles par colonne :\")\n",
    "for col in df.columns:\n",
    "    nb_nulls = df.filter(F.col(col).isNull()).count()\n",
    "    print(f\"  {col}: {nb_nulls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb2ea5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apres dropna() : 6 lignes\n"
     ]
    }
   ],
   "source": [
    "# Option 1 : Supprimer les lignes avec des nulls\n",
    "df_drop_na = df.dropna()\n",
    "print(f\"Apres dropna() : {df_drop_na.count()} lignes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e720cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------------+-------------+---+-------+\n",
      "| id|    nom|              email|        ville|age|salaire|\n",
      "+---+-------+-------------------+-------------+---+-------+\n",
      "|  1|  Alice|    alice@email.com|        Paris| 25|50000.0|\n",
      "|  2|    Bob|      BOB@EMAIL.COM|        paris| 30|60000.0|\n",
      "|  4|  Diana|    diana@email.com|  Marseille  | -5|70000.0|\n",
      "|  5|    Eve|          eve@email|     Toulouse| 28|55000.0|\n",
      "|  6|  Frank|    frank@email.com|             | 40|80000.0|\n",
      "|  7|  Grace|    grace@email.com|         Nice|150|65000.0|\n",
      "|  3|Charlie|inconnu@example.com|         Lyon| 35|    0.0|\n",
      "+---+-------+-------------------+-------------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Option 2 : Remplacer les nulls par des valeurs par defaut\n",
    "df_fill = df.fillna({\n",
    "    \"email\": \"inconnu@example.com\",\n",
    "    \"salaire\": 0.0\n",
    "})\n",
    "\n",
    "df_fill.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c9cb136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salaire moyen : 63333.333333333336\n",
      "+---+-------+---------------+-------------+---+------------------+\n",
      "| id|    nom|          email|        ville|age|           salaire|\n",
      "+---+-------+---------------+-------------+---+------------------+\n",
      "|  1|  Alice|alice@email.com|        Paris| 25|           50000.0|\n",
      "|  2|    Bob|  BOB@EMAIL.COM|        paris| 30|           60000.0|\n",
      "|  4|  Diana|diana@email.com|  Marseille  | -5|           70000.0|\n",
      "|  5|    Eve|      eve@email|     Toulouse| 28|           55000.0|\n",
      "|  6|  Frank|frank@email.com|             | 40|           80000.0|\n",
      "|  7|  Grace|grace@email.com|         Nice|150|           65000.0|\n",
      "|  3|Charlie|           NULL|         Lyon| 35|63333.333333333336|\n",
      "+---+-------+---------------+-------------+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Option 3 : Remplacer par la moyenne (pour les numeriques)\n",
    "moyenne_salaire = df.agg(F.avg(\"salaire\")).collect()[0][0]\n",
    "print(f\"Salaire moyen : {moyenne_salaire}\")\n",
    "\n",
    "df_fill_avg = df.fillna({\"salaire\": moyenne_salaire})\n",
    "df_fill_avg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1e35a5",
   "metadata": {},
   "source": [
    "## 6. Standardiser les formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24339268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apres standardisation :\n",
      "+---+-------+-------------------+---------+---+-------+\n",
      "|id |nom    |email              |ville    |age|salaire|\n",
      "+---+-------+-------------------+---------+---+-------+\n",
      "|1  |Alice  |alice@email.com    |Paris    |25 |50000.0|\n",
      "|2  |Bob    |bob@email.com      |Paris    |30 |60000.0|\n",
      "|4  |Diana  |diana@email.com    |Marseille|-5 |70000.0|\n",
      "|5  |Eve    |eve@email          |Toulouse |28 |55000.0|\n",
      "|6  |Frank  |frank@email.com    |         |40 |80000.0|\n",
      "|7  |Grace  |grace@email.com    |Nice     |150|65000.0|\n",
      "|3  |Charlie|inconnu@example.com|Lyon     |35 |0.0    |\n",
      "+---+-------+-------------------+---------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Appliquer plusieurs nettoyages\n",
    "df_clean = df_fill \\\n",
    "    .withColumn(\"email\", F.lower(F.col(\"email\"))) \\\n",
    "    .withColumn(\"ville\", F.trim(F.col(\"ville\"))) \\\n",
    "    .withColumn(\"ville\", F.initcap(F.col(\"ville\"))) \\\n",
    "    .withColumn(\"nom\", F.initcap(F.col(\"nom\")))\n",
    "\n",
    "print(\"Apres standardisation :\")\n",
    "df_clean.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57cfe13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------------+---------+---+-------+\n",
      "|id |nom    |email              |ville    |age|salaire|\n",
      "+---+-------+-------------------+---------+---+-------+\n",
      "|1  |Alice  |alice@email.com    |Paris    |25 |50000.0|\n",
      "|2  |Bob    |bob@email.com      |Paris    |30 |60000.0|\n",
      "|4  |Diana  |diana@email.com    |Marseille|-5 |70000.0|\n",
      "|5  |Eve    |eve@email          |Toulouse |28 |55000.0|\n",
      "|6  |Frank  |frank@email.com    |Inconnue |40 |80000.0|\n",
      "|7  |Grace  |grace@email.com    |Nice     |150|65000.0|\n",
      "|3  |Charlie|inconnu@example.com|Lyon     |35 |0.0    |\n",
      "+---+-------+-------------------+---------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Traiter les villes vides\n",
    "df_clean = df_clean.withColumn(\n",
    "    \"ville\",\n",
    "    F.when(F.col(\"ville\") == \"\", \"Inconnue\").otherwise(F.col(\"ville\"))\n",
    ")\n",
    "\n",
    "df_clean.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7230755",
   "metadata": {},
   "source": [
    "## 7. Valider les donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aea4ae68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ages invalides :\n",
      "+---+-----+---------------+---------+---+-------+----------+\n",
      "| id|  nom|          email|    ville|age|salaire|age_valide|\n",
      "+---+-----+---------------+---------+---+-------+----------+\n",
      "|  4|Diana|diana@email.com|Marseille| -5|70000.0|     false|\n",
      "|  7|Grace|grace@email.com|     Nice|150|65000.0|     false|\n",
      "+---+-----+---------------+---------+---+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Valider l'age (entre 0 et 120)\n",
    "df_valid = df_clean.withColumn(\n",
    "    \"age_valide\",\n",
    "    F.when((F.col(\"age\") >= 0) & (F.col(\"age\") <= 120), True).otherwise(False)\n",
    ")\n",
    "\n",
    "print(\"Ages invalides :\")\n",
    "df_valid.filter(F.col(\"age_valide\") == False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f5985c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------------+---------+----+-------+\n",
      "| id|    nom|              email|    ville| age|salaire|\n",
      "+---+-------+-------------------+---------+----+-------+\n",
      "|  1|  Alice|    alice@email.com|    Paris|  25|50000.0|\n",
      "|  2|    Bob|      bob@email.com|    Paris|  30|60000.0|\n",
      "|  4|  Diana|    diana@email.com|Marseille|NULL|70000.0|\n",
      "|  5|    Eve|          eve@email| Toulouse|  28|55000.0|\n",
      "|  6|  Frank|    frank@email.com| Inconnue|  40|80000.0|\n",
      "|  7|  Grace|    grace@email.com|     Nice|NULL|65000.0|\n",
      "|  3|Charlie|inconnu@example.com|     Lyon|  35|    0.0|\n",
      "+---+-------+-------------------+---------+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Corriger ou filtrer les ages invalides\n",
    "df_age_corrige = df_clean.withColumn(\n",
    "    \"age\",\n",
    "    F.when(F.col(\"age\") < 0, None)\n",
    "     .when(F.col(\"age\") > 120, None)\n",
    "     .otherwise(F.col(\"age\"))\n",
    ")\n",
    "\n",
    "df_age_corrige.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8bc3b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails invalides :\n",
      "+---+---+---------+--------+---+-------+------------+\n",
      "|id |nom|email    |ville   |age|salaire|email_valide|\n",
      "+---+---+---------+--------+---+-------+------------+\n",
      "|5  |Eve|eve@email|Toulouse|28 |55000.0|false       |\n",
      "+---+---+---------+--------+---+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Valider le format email avec regex\n",
    "pattern_email = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "\n",
    "df_email_valide = df_age_corrige.withColumn(\n",
    "    \"email_valide\",\n",
    "    F.col(\"email\").rlike(pattern_email)\n",
    ")\n",
    "\n",
    "print(\"Emails invalides :\")\n",
    "df_email_valide.filter(F.col(\"email_valide\") == False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0596ecb",
   "metadata": {},
   "source": [
    "## 8. Pipeline de nettoyage complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4910726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettoyer_donnees(df):\n",
    "    \"\"\"\n",
    "    Pipeline de nettoyage complet.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame brut (Bronze)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame nettoye (Silver)\n",
    "    \"\"\"\n",
    "    # 1. Supprimer les doublons\n",
    "    df = df.dropDuplicates([\"id\"])\n",
    "    \n",
    "    # 2. Gerer les nulls\n",
    "    df = df.fillna({\n",
    "        \"email\": \"inconnu@example.com\",\n",
    "        \"ville\": \"Inconnue\",\n",
    "        \"salaire\": 0.0\n",
    "    })\n",
    "    \n",
    "    # 3. Standardiser les formats\n",
    "    df = df.withColumn(\"email\", F.lower(F.trim(F.col(\"email\")))) \\\n",
    "           .withColumn(\"ville\", F.initcap(F.trim(F.col(\"ville\")))) \\\n",
    "           .withColumn(\"nom\", F.initcap(F.trim(F.col(\"nom\"))))\n",
    "    \n",
    "    # 4. Traiter les villes vides\n",
    "    df = df.withColumn(\n",
    "        \"ville\",\n",
    "        F.when(F.col(\"ville\") == \"\", \"Inconnue\").otherwise(F.col(\"ville\"))\n",
    "    )\n",
    "    \n",
    "    # 5. Valider et corriger l'age\n",
    "    df = df.withColumn(\n",
    "        \"age\",\n",
    "        F.when((F.col(\"age\") >= 0) & (F.col(\"age\") <= 120), F.col(\"age\"))\n",
    "         .otherwise(None)\n",
    "    )\n",
    "    \n",
    "    # 6. Ajouter les metadonnees\n",
    "    df = df.withColumn(\"_cleaned_date\", F.lit(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00506f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donnees nettoyees (Silver) :\n",
      "+---+-------+-------------------+---------+----+-------+-------------------+\n",
      "|id |nom    |email              |ville    |age |salaire|_cleaned_date      |\n",
      "+---+-------+-------------------+---------+----+-------+-------------------+\n",
      "|1  |Alice  |alice@email.com    |Paris    |25  |50000.0|2026-01-15 16:02:11|\n",
      "|2  |Bob    |bob@email.com      |Paris    |30  |60000.0|2026-01-15 16:02:11|\n",
      "|3  |Charlie|inconnu@example.com|Lyon     |35  |0.0    |2026-01-15 16:02:11|\n",
      "|4  |Diana  |diana@email.com    |Marseille|NULL|70000.0|2026-01-15 16:02:11|\n",
      "|5  |Eve    |eve@email          |Toulouse |28  |55000.0|2026-01-15 16:02:11|\n",
      "|6  |Frank  |frank@email.com    |Inconnue |40  |80000.0|2026-01-15 16:02:11|\n",
      "|7  |Grace  |grace@email.com    |Nice     |NULL|65000.0|2026-01-15 16:02:11|\n",
      "+---+-------+-------------------+---------+----+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Appliquer le pipeline\n",
    "df_silver = nettoyer_donnees(df_bronze)\n",
    "\n",
    "print(\"Donnees nettoyees (Silver) :\")\n",
    "df_silver.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd0e310",
   "metadata": {},
   "source": [
    "## 9. Rapport de qualite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5df9daee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "RAPPORT DE QUALITE\n",
      "==================================================\n",
      "\n",
      "Lignes avant  : 8\n",
      "Lignes apres  : 7\n",
      "Lignes retirees: 1\n",
      "\n",
      "Valeurs nulles (apres nettoyage) :\n",
      "  id: 0 (0.0%)\n",
      "  nom: 0 (0.0%)\n",
      "  email: 0 (0.0%)\n",
      "  ville: 0 (0.0%)\n",
      "  age: 2 (28.6%)\n",
      "  salaire: 0 (0.0%)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def rapport_qualite(df_avant, df_apres):\n",
    "    \"\"\"\n",
    "    Genere un rapport de qualite des donnees.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"RAPPORT DE QUALITE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"\\nLignes avant  : {df_avant.count()}\")\n",
    "    print(f\"Lignes apres  : {df_apres.count()}\")\n",
    "    print(f\"Lignes retirees: {df_avant.count() - df_apres.count()}\")\n",
    "    \n",
    "    print(\"\\nValeurs nulles (apres nettoyage) :\")\n",
    "    for col in df_apres.columns:\n",
    "        if not col.startswith(\"_\"):\n",
    "            nb_nulls = df_apres.filter(F.col(col).isNull()).count()\n",
    "            pct = (nb_nulls / df_apres.count()) * 100 if df_apres.count() > 0 else 0\n",
    "            print(f\"  {col}: {nb_nulls} ({pct:.1f}%)\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "\n",
    "rapport_qualite(df_bronze, df_silver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdba930",
   "metadata": {},
   "source": [
    "## 10. Sauvegarder dans Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2f0c16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauvegarde Silver : s3a://silver/users/2026-01-15\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder les donnees nettoyees\n",
    "chemin_silver = f\"s3a://silver/users/{date_traitement}\"\n",
    "df_silver.write.mode(\"overwrite\").parquet(chemin_silver)\n",
    "\n",
    "print(f\"Sauvegarde Silver : {chemin_silver}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f19095",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice\n",
    "\n",
    "**Objectif** : Nettoyer les donnees Northwind customers\n",
    "\n",
    "**Consigne** :\n",
    "1. Lisez la table `customers` depuis PostgreSQL ou Bronze\n",
    "2. Appliquez les nettoyages suivants :\n",
    "   - Standardisez les noms de pays (majuscules)\n",
    "   - Supprimez les espaces en debut/fin de texte\n",
    "   - Gerez les valeurs nulles\n",
    "3. Sauvegardez dans Silver\n",
    "\n",
    "A vous de jouer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5107111e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de clients chargés : 91\n",
      "+-----------+--------------------+------------------+--------------------+--------------------+-----------+------+-----------+-------+--------------+--------------+\n",
      "|customer_id|        company_name|      contact_name|       contact_title|             address|       city|region|postal_code|country|         phone|           fax|\n",
      "+-----------+--------------------+------------------+--------------------+--------------------+-----------+------+-----------+-------+--------------+--------------+\n",
      "|      ALFKI| Alfreds Futterkiste|      Maria Anders|Sales Representative|       Obere Str. 57|     Berlin|  NULL|      12209|Germany|   030-0074321|   030-0076545|\n",
      "|      ANATR|Ana Trujillo Empa...|      Ana Trujillo|               Owner|Avda. de la Const...|México D.F.|  NULL|      05021| Mexico|  (5) 555-4729|  (5) 555-3745|\n",
      "|      ANTON|Antonio Moreno Ta...|    Antonio Moreno|               Owner|     Mataderos  2312|México D.F.|  NULL|      05023| Mexico|  (5) 555-3932|          NULL|\n",
      "|      AROUT|     Around the Horn|      Thomas Hardy|Sales Representative|     120 Hanover Sq.|     London|  NULL|    WA1 1DP|     UK|(171) 555-7788|(171) 555-6750|\n",
      "|      BERGS|  Berglunds snabbköp|Christina Berglund| Order Administrator|     Berguvsvägen  8|      Luleå|  NULL|   S-958 22| Sweden| 0921-12 34 65| 0921-12 34 67|\n",
      "+-----------+--------------------+------------------+--------------------+--------------------+-----------+------+-----------+-------+--------------+--------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# TODO: Lire les customers depuis PostgreSQL\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/app\"\n",
    "jdbc_properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "df_customers = spark.read.jdbc(url=jdbc_url, table=\"customers\", properties=jdbc_properties)\n",
    "print(f\"Nombre de clients chargés : {df_customers.count()}\")\n",
    "df_customers.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd39e85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des données nettoyées :\n",
      "+-----------+--------------------+-----------+-------+------------+\n",
      "|customer_id|        company_name|       city|country|      region|\n",
      "+-----------+--------------------+-----------+-------+------------+\n",
      "|      ALFKI| Alfreds Futterkiste|     Berlin|GERMANY|Non spécifié|\n",
      "|      ANATR|Ana Trujillo Empa...|México D.f.| MEXICO|Non spécifié|\n",
      "|      ANTON|Antonio Moreno Ta...|México D.f.| MEXICO|Non spécifié|\n",
      "|      AROUT|     Around the Horn|     London|     UK|Non spécifié|\n",
      "|      BERGS|  Berglunds snabbköp|      Luleå| SWEDEN|Non spécifié|\n",
      "+-----------+--------------------+-----------+-------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# TODO: Appliquer les nettoyages\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Nettoyage de base sur les strings\n",
    "df_clean = df_customers\n",
    "for col_name, dtype in df_customers.dtypes:\n",
    "    if dtype == \"string\":\n",
    "        df_clean = df_clean.withColumn(col_name, F.trim(F.col(col_name)))\n",
    "\n",
    "# Standardisation et gestion des NULLs\n",
    "df_silver_customers = df_clean \\\n",
    "    .withColumn(\"country\", F.upper(F.col(\"country\"))) \\\n",
    "    .withColumn(\"city\", F.initcap(F.col(\"city\"))) \\\n",
    "    .fillna({\n",
    "        \"region\": \"Non spécifié\",\n",
    "        \"fax\": \"Non renseigné\"\n",
    "    }) \\\n",
    "    .dropDuplicates([\"customer_id\"])\n",
    "\n",
    "print(\"Aperçu des données nettoyées :\")\n",
    "df_silver_customers.select(\"customer_id\", \"company_name\", \"city\", \"country\", \"region\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a78d2dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauvegarde Silver terminée avec succès : s3a://silver/customers/2026-01-15\n",
      "Nombre de clients sauvegardés : 91\n"
     ]
    }
   ],
   "source": [
    "# TODO: Sauvegarder dans Silver\n",
    "from datetime import datetime\n",
    "\n",
    "date_traitement = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "chemin_silver = f\"s3a://silver/customers/{date_traitement}\"\n",
    "\n",
    "df_final = df_silver_customers.withColumn(\"_cleaned_at\", F.current_timestamp())\n",
    "\n",
    "# Écriture\n",
    "df_final.write.mode(\"overwrite\").parquet(chemin_silver)\n",
    "\n",
    "print(f\"Sauvegarde Silver terminée avec succès : {chemin_silver}\")\n",
    "print(f\"Nombre de clients sauvegardés : {df_final.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead3864f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Resume\n",
    "\n",
    "Dans ce notebook, vous avez appris :\n",
    "- Le role de la couche **Silver** dans un Data Lake\n",
    "- Comment **supprimer les doublons** avec dropDuplicates()\n",
    "- Comment **gerer les valeurs nulles** avec dropna() et fillna()\n",
    "- Comment **standardiser les formats** (trim, lower, initcap)\n",
    "- Comment **valider les donnees** avec des regles metier\n",
    "- Comment creer un **pipeline de nettoyage** reutilisable\n",
    "\n",
    "### Prochaine etape\n",
    "Dans le prochain notebook, nous apprendrons les transformations avancees pour la couche Silver."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
