{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e221f8d8",
   "metadata": {},
   "source": [
    "# Exercice 12 - Operations DataFrame avancees\n",
    "\n",
    "## Objectifs\n",
    "- Maitriser les operations de pivot\n",
    "- Utiliser les User Defined Functions (UDF)\n",
    "- Travailler avec les types complexes (arrays, maps)\n",
    "- Optimiser les performances des DataFrames\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd5e87",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ce83fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark pret\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType, MapType, StructType, StructField\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Operations DataFrame Avancees\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.6.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark pret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d4019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donnees chargees\n"
     ]
    }
   ],
   "source": [
    "# Charger les donnees\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/app\"\n",
    "jdbc_properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "df_orders = spark.read.jdbc(url=jdbc_url, table=\"orders\", properties=jdbc_properties)\n",
    "df_order_details = spark.read.jdbc(url=jdbc_url, table=\"order_details\", properties=jdbc_properties)\n",
    "df_products = spark.read.jdbc(url=jdbc_url, table=\"products\", properties=jdbc_properties)\n",
    "df_customers = spark.read.jdbc(url=jdbc_url, table=\"customers\", properties=jdbc_properties)\n",
    "\n",
    "print(\"Donnees chargees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010d6092",
   "metadata": {},
   "source": [
    "## 2. Pivot et Unpivot\n",
    "\n",
    "```\n",
    "PIVOT : Lignes -> Colonnes\n",
    "\n",
    "Avant:                          Apres:\n",
    "+-------+------+-------+        +-------+--------+--------+--------+\n",
    "| annee | mois | ventes|   -->  | annee | Jan    | Fev    | Mar    |\n",
    "+-------+------+-------+        +-------+--------+--------+--------+\n",
    "| 2023  | Jan  | 100   |        | 2023  | 100    | 200    | 150    |\n",
    "| 2023  | Fev  | 200   |        | 2024  | 120    | 180    | 160    |\n",
    "| 2023  | Mar  | 150   |        +-------+--------+--------+--------+\n",
    "| 2024  | Jan  | 120   |\n",
    "+-------+------+-------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec8d9ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---------+\n",
      "|annee|mois|       ca|\n",
      "+-----+----+---------+\n",
      "| 1996|   7|  30192.1|\n",
      "| 1996|   8|  26609.4|\n",
      "| 1996|   9|  27636.0|\n",
      "| 1996|  10|  41203.6|\n",
      "| 1996|  11|  49704.0|\n",
      "| 1996|  12|  50953.4|\n",
      "| 1997|   1|  66692.8|\n",
      "| 1997|   2|  41207.2|\n",
      "| 1997|   3|  39979.9|\n",
      "| 1997|   4| 55699.39|\n",
      "| 1997|   5|  56823.7|\n",
      "| 1997|   6|  39088.0|\n",
      "| 1997|   7| 55464.93|\n",
      "| 1997|   8| 49981.69|\n",
      "| 1997|   9| 59733.02|\n",
      "| 1997|  10|  70328.5|\n",
      "| 1997|  11| 45913.36|\n",
      "| 1997|  12| 77476.26|\n",
      "| 1998|   1|100854.72|\n",
      "| 1998|   2|104561.95|\n",
      "+-----+----+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Preparer les donnees de ventes\n",
    "df_ventes = df_order_details.join(df_orders.select(\"order_id\", \"order_date\"), on=\"order_id\")\n",
    "df_ventes = df_ventes.withColumn(\n",
    "    \"montant\",\n",
    "    F.round(F.col(\"unit_price\") * F.col(\"quantity\"), 2)\n",
    ").withColumn(\n",
    "    \"annee\", F.year(\"order_date\")\n",
    ").withColumn(\n",
    "    \"mois\", F.month(\"order_date\")\n",
    ")\n",
    "\n",
    "# Agreger par annee et mois\n",
    "df_mensuel = df_ventes.groupBy(\"annee\", \"mois\").agg(\n",
    "    F.round(F.sum(\"montant\"), 2).alias(\"ca\")\n",
    ")\n",
    "\n",
    "df_mensuel.orderBy(\"annee\", \"mois\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2763b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tableau pivot par mois :\n",
      "+-----+---------+---------+---------+---------+--------+-------+--------+--------+--------+-------+--------+--------+\n",
      "|annee|        1|        2|        3|        4|       5|      6|       7|       8|       9|     10|      11|      12|\n",
      "+-----+---------+---------+---------+---------+--------+-------+--------+--------+--------+-------+--------+--------+\n",
      "| 1996|     NULL|     NULL|     NULL|     NULL|    NULL|   NULL| 30192.1| 26609.4| 27636.0|41203.6| 49704.0| 50953.4|\n",
      "| 1997|  66692.8|  41207.2|  39979.9| 55699.39| 56823.7|39088.0|55464.93|49981.69|59733.02|70328.5|45913.36|77476.26|\n",
      "| 1998|100854.72|104561.95|109825.45|134630.56|19898.66|   NULL|    NULL|    NULL|    NULL|   NULL|    NULL|    NULL|\n",
      "+-----+---------+---------+---------+---------+--------+-------+--------+--------+--------+-------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PIVOT : mois en colonnes\n",
    "df_pivot = df_mensuel.groupBy(\"annee\").pivot(\"mois\").agg(F.first(\"ca\"))\n",
    "\n",
    "print(\"Tableau pivot par mois :\")\n",
    "df_pivot.orderBy(\"annee\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63f4057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------+---------+---------+--------+-------+--------+--------+--------+-------+--------+--------+\n",
      "|annee|        1|        2|        3|        4|       5|      6|       7|       8|       9|     10|      11|      12|\n",
      "+-----+---------+---------+---------+---------+--------+-------+--------+--------+--------+-------+--------+--------+\n",
      "| 1997|  66692.8|  41207.2|  39979.9| 55699.39| 56823.7|39088.0|55464.93|49981.69|59733.02|70328.5|45913.36|77476.26|\n",
      "| 1996|      0.0|      0.0|      0.0|      0.0|     0.0|    0.0| 30192.1| 26609.4| 27636.0|41203.6| 49704.0| 50953.4|\n",
      "| 1998|100854.72|104561.95|109825.45|134630.56|19898.66|    0.0|     0.0|     0.0|     0.0|    0.0|     0.0|     0.0|\n",
      "+-----+---------+---------+---------+---------+--------+-------+--------+--------+--------+-------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pivot avec liste de valeurs (plus performant)\n",
    "mois_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "df_pivot_opt = df_mensuel.groupBy(\"annee\").pivot(\"mois\", mois_list).agg(F.first(\"ca\")).fillna(0)\n",
    "\n",
    "df_pivot_opt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "848f6efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apres unpivot :\n",
      "+-----+----+--------+\n",
      "|annee|mois|      ca|\n",
      "+-----+----+--------+\n",
      "| 1996|   1|     0.0|\n",
      "| 1996|   2|     0.0|\n",
      "| 1996|   3|     0.0|\n",
      "| 1996|   4|     0.0|\n",
      "| 1996|   5|     0.0|\n",
      "| 1996|   6|     0.0|\n",
      "| 1996|   7| 30192.1|\n",
      "| 1996|   8| 26609.4|\n",
      "| 1996|   9| 27636.0|\n",
      "| 1996|  10| 41203.6|\n",
      "| 1996|  11| 49704.0|\n",
      "| 1996|  12| 50953.4|\n",
      "| 1997|   1| 66692.8|\n",
      "| 1997|   2| 41207.2|\n",
      "| 1997|   3| 39979.9|\n",
      "| 1997|   4|55699.39|\n",
      "| 1997|   5| 56823.7|\n",
      "| 1997|   6| 39088.0|\n",
      "| 1997|   7|55464.93|\n",
      "| 1997|   8|49981.69|\n",
      "+-----+----+--------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# UNPIVOT : Colonnes -> Lignes\n",
    "# Spark n'a pas de fonction unpivot native, on utilise stack()\n",
    "colonnes_mois = [f\"`{i}` as mois_{i}\" for i in range(1, 13)]\n",
    "\n",
    "df_unpivot = df_pivot_opt.select(\n",
    "    \"annee\",\n",
    "    F.expr(f\"stack(12, {', '.join([f'{i}, `{i}`' for i in range(1, 13)])}) as (mois, ca)\")\n",
    ").filter(F.col(\"ca\").isNotNull())\n",
    "\n",
    "print(\"Apres unpivot :\")\n",
    "df_unpivot.orderBy(\"annee\", \"mois\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7a3cf7",
   "metadata": {},
   "source": [
    "## 3. User Defined Functions (UDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e09ce171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----------+\n",
      "|        product_name|unit_price|niveau_prix|\n",
      "+--------------------+----------+-----------+\n",
      "|                Chai|      18.0|   Standard|\n",
      "|               Chang|      19.0|   Standard|\n",
      "|       Aniseed Syrup|      10.0|   Standard|\n",
      "|Chef Anton's Caju...|      22.0|   Standard|\n",
      "|Chef Anton's Gumb...|     21.35|   Standard|\n",
      "|Grandma's Boysenb...|      25.0|    Premium|\n",
      "|Uncle Bob's Organ...|      30.0|    Premium|\n",
      "|Northwoods Cranbe...|      40.0|    Premium|\n",
      "|     Mishi Kobe Niku|      97.0|       Luxe|\n",
      "|               Ikura|      31.0|    Premium|\n",
      "+--------------------+----------+-----------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# Definir une fonction Python\n",
    "def categoriser_prix(prix):\n",
    "    \"\"\"Categorise un prix en niveau\"\"\"\n",
    "    if prix is None:\n",
    "        return \"Inconnu\"\n",
    "    elif prix < 10:\n",
    "        return \"Economique\"\n",
    "    elif prix < 25:\n",
    "        return \"Standard\"\n",
    "    elif prix < 50:\n",
    "        return \"Premium\"\n",
    "    else:\n",
    "        return \"Luxe\"\n",
    "\n",
    "# Enregistrer comme UDF\n",
    "categoriser_prix_udf = udf(categoriser_prix, StringType())\n",
    "\n",
    "# Utiliser l'UDF\n",
    "df_products_cat = df_products.withColumn(\n",
    "    \"niveau_prix\",\n",
    "    categoriser_prix_udf(F.col(\"unit_price\"))\n",
    ")\n",
    "\n",
    "df_products_cat.select(\"product_name\", \"unit_price\", \"niveau_prix\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eb63f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+-----------+\n",
      "|        company_name|         phone|phone_clean|\n",
      "+--------------------+--------------+-----------+\n",
      "| Alfreds Futterkiste|   030-0074321| 0300074321|\n",
      "|Ana Trujillo Empa...|  (5) 555-4729|   55554729|\n",
      "|Antonio Moreno Ta...|  (5) 555-3932|   55553932|\n",
      "|     Around the Horn|(171) 555-7788| 1715557788|\n",
      "|  Berglunds snabbköp| 0921-12 34 65| 0921123465|\n",
      "|Blauer See Delika...|    0621-08460|  062108460|\n",
      "|Blondesddsl père ...|   88.60.15.31|   88601531|\n",
      "|Bólido Comidas pr...|(91) 555 22 82|  915552282|\n",
      "|            Bon app'|   91.24.45.40|   91244540|\n",
      "|Bottom-Dollar Mar...|(604) 555-4729| 6045554729|\n",
      "+--------------------+--------------+-----------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# UDF avec decorateur (plus lisible)\n",
    "@udf(returnType=StringType())\n",
    "def format_telephone(phone):\n",
    "    \"\"\"Formate un numero de telephone\"\"\"\n",
    "    if phone is None:\n",
    "        return None\n",
    "    # Garder seulement les chiffres\n",
    "    digits = ''.join(filter(str.isdigit, phone))\n",
    "    return digits if len(digits) > 0 else None\n",
    "\n",
    "df_customers.withColumn(\n",
    "    \"phone_clean\",\n",
    "    format_telephone(F.col(\"phone\"))\n",
    ").select(\"company_name\", \"phone\", \"phone_clean\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da25a0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------------------+\n",
      "|product_name                |mots_nom                         |\n",
      "+----------------------------+---------------------------------+\n",
      "|Chai                        |[Chai]                           |\n",
      "|Chang                       |[Chang]                          |\n",
      "|Aniseed Syrup               |[Aniseed, Syrup]                 |\n",
      "|Chef Anton's Cajun Seasoning|[Chef, Anton's, Cajun, Seasoning]|\n",
      "|Chef Anton's Gumbo Mix      |[Chef, Anton's, Gumbo, Mix]      |\n",
      "+----------------------------+---------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# UDF retournant une structure complexe\n",
    "@udf(returnType=ArrayType(StringType()))\n",
    "def extraire_mots(texte):\n",
    "    \"\"\"Extrait les mots d'un texte\"\"\"\n",
    "    if texte is None:\n",
    "        return []\n",
    "    return texte.split()\n",
    "\n",
    "df_products.withColumn(\n",
    "    \"mots_nom\",\n",
    "    extraire_mots(F.col(\"product_name\"))\n",
    ").select(\"product_name\", \"mots_nom\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfe8cdc",
   "metadata": {},
   "source": [
    "## 4. Pandas UDF (plus performant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c902307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+---------------+\n",
      "|order_id|unit_price|quantity|remise_calculee|\n",
      "+--------+----------+--------+---------------+\n",
      "|   10248|      14.0|      12|           0.05|\n",
      "|   10248|       9.8|      10|            0.0|\n",
      "|   10248|      34.8|       5|           0.05|\n",
      "|   10249|      18.6|       9|           0.05|\n",
      "|   10249|      42.4|      40|           0.15|\n",
      "|   10250|       7.7|      10|            0.0|\n",
      "|   10250|      42.4|      35|           0.15|\n",
      "|   10250|      16.8|      15|           0.05|\n",
      "|   10251|      16.8|       6|           0.05|\n",
      "|   10251|      15.6|      15|           0.05|\n",
      "+--------+----------+--------+---------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "\n",
    "# Pandas UDF (vectorisee, beaucoup plus rapide)\n",
    "@pandas_udf(\"double\")\n",
    "def calculer_remise(prix: pd.Series, quantite: pd.Series) -> pd.Series:\n",
    "    \"\"\"Calcule une remise progressive\"\"\"\n",
    "    montant = prix * quantite\n",
    "    remise = pd.Series([0.0] * len(montant))\n",
    "    remise[montant >= 100] = 0.05\n",
    "    remise[montant >= 500] = 0.10\n",
    "    remise[montant >= 1000] = 0.15\n",
    "    return remise\n",
    "\n",
    "df_order_details.withColumn(\n",
    "    \"remise_calculee\",\n",
    "    calculer_remise(F.col(\"unit_price\"), F.col(\"quantity\"))\n",
    ").select(\"order_id\", \"unit_price\", \"quantity\", \"remise_calculee\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cfa855",
   "metadata": {},
   "source": [
    "## 5. Types complexes : Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e780d35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------------------------------------------------------------------+------------+\n",
      "|order_id|produits                                                                                  |product_ids |\n",
      "+--------+------------------------------------------------------------------------------------------+------------+\n",
      "|10248   |[Mozzarella di Giovanni, Queso Cabrales, Singaporean Hokkien Fried Mee]                   |[72, 42, 11]|\n",
      "|10249   |[Manjimup Dried Apples, Tofu]                                                             |[51, 14]    |\n",
      "|10250   |[Jack's New England Clam Chowder, Manjimup Dried Apples, Louisiana Fiery Hot Pepper Sauce]|[65, 51, 41]|\n",
      "|10251   |[Gustaf's Knäckebröd, Ravioli Angelo, Louisiana Fiery Hot Pepper Sauce]                   |[65, 22, 57]|\n",
      "|10252   |[Sir Rodney's Marmalade, Camembert Pierrot, Geitost]                                      |[33, 20, 60]|\n",
      "+--------+------------------------------------------------------------------------------------------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Creer un array des produits par commande\n",
    "df_produits_commande = df_order_details.join(\n",
    "    df_products.select(\"product_id\", \"product_name\"),\n",
    "    on=\"product_id\"\n",
    ").groupBy(\"order_id\").agg(\n",
    "    F.collect_list(\"product_name\").alias(\"produits\"),\n",
    "    F.collect_set(\"product_id\").alias(\"product_ids\")\n",
    ")\n",
    "\n",
    "df_produits_commande.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38b3cbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------------------------+------------------------------------------------------------------------------------------+\n",
      "|order_id|nb_produits|premier_produit                |produits_tries                                                                            |\n",
      "+--------+-----------+-------------------------------+------------------------------------------------------------------------------------------+\n",
      "|10248   |3          |Mozzarella di Giovanni         |[Mozzarella di Giovanni, Queso Cabrales, Singaporean Hokkien Fried Mee]                   |\n",
      "|10249   |2          |Manjimup Dried Apples          |[Manjimup Dried Apples, Tofu]                                                             |\n",
      "|10250   |3          |Jack's New England Clam Chowder|[Jack's New England Clam Chowder, Louisiana Fiery Hot Pepper Sauce, Manjimup Dried Apples]|\n",
      "|10251   |3          |Gustaf's Knäckebröd            |[Gustaf's Knäckebröd, Louisiana Fiery Hot Pepper Sauce, Ravioli Angelo]                   |\n",
      "|10252   |3          |Sir Rodney's Marmalade         |[Camembert Pierrot, Geitost, Sir Rodney's Marmalade]                                      |\n",
      "+--------+-----------+-------------------------------+------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Operations sur les arrays\n",
    "df_array_ops = df_produits_commande.withColumn(\n",
    "    \"nb_produits\",\n",
    "    F.size(\"produits\")\n",
    ").withColumn(\n",
    "    \"premier_produit\",\n",
    "    F.element_at(\"produits\", 1)\n",
    ").withColumn(\n",
    "    \"produits_tries\",\n",
    "    F.sort_array(\"produits\")\n",
    ")\n",
    "\n",
    "df_array_ops.select(\"order_id\", \"nb_produits\", \"premier_produit\", \"produits_tries\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "484ca77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apres explode :\n",
      "+--------+--------------------+\n",
      "|order_id|             produit|\n",
      "+--------+--------------------+\n",
      "|   10248|Mozzarella di Gio...|\n",
      "|   10248|      Queso Cabrales|\n",
      "|   10248|Singaporean Hokki...|\n",
      "|   10249|Manjimup Dried Ap...|\n",
      "|   10249|                Tofu|\n",
      "|   10250|Jack's New Englan...|\n",
      "|   10250|Manjimup Dried Ap...|\n",
      "|   10250|Louisiana Fiery H...|\n",
      "|   10251| Gustaf's Knäckebröd|\n",
      "|   10251|      Ravioli Angelo|\n",
      "+--------+--------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Explode : Array -> Lignes multiples\n",
    "df_explode = df_produits_commande.select(\n",
    "    \"order_id\",\n",
    "    F.explode(\"produits\").alias(\"produit\")\n",
    ")\n",
    "\n",
    "print(\"Apres explode :\")\n",
    "df_explode.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7e0209",
   "metadata": {},
   "source": [
    "## 6. Types complexes : Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b70b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------------------------------------------------------------------------------------+\n",
      "|order_id|produits_quantites                                                                                          |\n",
      "+--------+------------------------------------------------------------------------------------------------------------+\n",
      "|10248   |{Mozzarella di Giovanni -> 5, Queso Cabrales -> 12, Singaporean Hokkien Fried Mee -> 10}                    |\n",
      "|10249   |{Manjimup Dried Apples -> 40, Tofu -> 9}                                                                    |\n",
      "|10250   |{Jack's New England Clam Chowder -> 10, Manjimup Dried Apples -> 35, Louisiana Fiery Hot Pepper Sauce -> 15}|\n",
      "+--------+------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "# Creer une map produit -> quantite par commande\n",
    "df_map = df_order_details.join(\n",
    "    df_products.select(\"product_id\", \"product_name\"),\n",
    "    on=\"product_id\"\n",
    ").groupBy(\"order_id\").agg(\n",
    "    F.map_from_entries(\n",
    "        F.collect_list(\n",
    "            F.struct(F.col(\"product_name\"), F.col(\"quantity\"))\n",
    "        )\n",
    "    ).alias(\"produits_quantites\")\n",
    ")\n",
    "\n",
    "df_map.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30e37ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------------------------------------------------------------------+--------------+\n",
      "|order_id|toutes_cles                                                                               |toutes_valeurs|\n",
      "+--------+------------------------------------------------------------------------------------------+--------------+\n",
      "|10248   |[Mozzarella di Giovanni, Queso Cabrales, Singaporean Hokkien Fried Mee]                   |[5, 12, 10]   |\n",
      "|10249   |[Manjimup Dried Apples, Tofu]                                                             |[40, 9]       |\n",
      "|10250   |[Jack's New England Clam Chowder, Manjimup Dried Apples, Louisiana Fiery Hot Pepper Sauce]|[10, 35, 15]  |\n",
      "+--------+------------------------------------------------------------------------------------------+--------------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "# Acceder aux valeurs d'une map\n",
    "df_map.withColumn(\n",
    "    \"toutes_cles\",\n",
    "    F.map_keys(\"produits_quantites\")\n",
    ").withColumn(\n",
    "    \"toutes_valeurs\",\n",
    "    F.map_values(\"produits_quantites\")\n",
    ").select(\"order_id\", \"toutes_cles\", \"toutes_valeurs\").show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35a32d8",
   "metadata": {},
   "source": [
    "## 7. Operations sur les Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74c578a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- company_name: string (nullable = true)\n",
      " |-- adresse_complete: struct (nullable = false)\n",
      " |    |-- rue: string (nullable = true)\n",
      " |    |-- ville: string (nullable = true)\n",
      " |    |-- code_postal: string (nullable = true)\n",
      " |    |-- pays: string (nullable = true)\n",
      "\n",
      "+-----------+----------------------------------+-----------------------------------------------------------+\n",
      "|customer_id|company_name                      |adresse_complete                                           |\n",
      "+-----------+----------------------------------+-----------------------------------------------------------+\n",
      "|ALFKI      |Alfreds Futterkiste               |{Obere Str. 57, Berlin, 12209, Germany}                    |\n",
      "|ANATR      |Ana Trujillo Emparedados y helados|{Avda. de la Constitución 2222, México D.F., 05021, Mexico}|\n",
      "|ANTON      |Antonio Moreno Taquería           |{Mataderos  2312, México D.F., 05023, Mexico}              |\n",
      "|AROUT      |Around the Horn                   |{120 Hanover Sq., London, WA1 1DP, UK}                     |\n",
      "|BERGS      |Berglunds snabbköp                |{Berguvsvägen  8, Luleå, S-958 22, Sweden}                 |\n",
      "+-----------+----------------------------------+-----------------------------------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Creer une structure imbriquee\n",
    "df_struct = df_customers.select(\n",
    "    \"customer_id\",\n",
    "    \"company_name\",\n",
    "    F.struct(\n",
    "        F.col(\"address\").alias(\"rue\"),\n",
    "        F.col(\"city\").alias(\"ville\"),\n",
    "        F.col(\"postal_code\").alias(\"code_postal\"),\n",
    "        F.col(\"country\").alias(\"pays\")\n",
    "    ).alias(\"adresse_complete\")\n",
    ")\n",
    "\n",
    "df_struct.printSchema()\n",
    "df_struct.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "594d79bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------+\n",
      "|        company_name|      ville|   pays|\n",
      "+--------------------+-----------+-------+\n",
      "| Alfreds Futterkiste|     Berlin|Germany|\n",
      "|Ana Trujillo Empa...|México D.F.| Mexico|\n",
      "|Antonio Moreno Ta...|México D.F.| Mexico|\n",
      "|     Around the Horn|     London|     UK|\n",
      "|  Berglunds snabbköp|      Luleå| Sweden|\n",
      "|Blauer See Delika...|   Mannheim|Germany|\n",
      "|Blondesddsl père ...| Strasbourg| France|\n",
      "|Bólido Comidas pr...|     Madrid|  Spain|\n",
      "|            Bon app'|  Marseille| France|\n",
      "|Bottom-Dollar Mar...|  Tsawassen| Canada|\n",
      "+--------------------+-----------+-------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Acceder aux champs d'une structure\n",
    "df_struct.select(\n",
    "    \"company_name\",\n",
    "    F.col(\"adresse_complete.ville\").alias(\"ville\"),\n",
    "    F.col(\"adresse_complete.pays\").alias(\"pays\")\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a927d46",
   "metadata": {},
   "source": [
    "## 8. Optimisation des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1461f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------------+-----------+-------------------+----------+--------------+--------------+-------------+------------+-------------+--------------------+-------+\n",
      "|category_id|product_id|        product_name|supplier_id|  quantity_per_unit|unit_price|units_in_stock|units_on_order|reorder_level|discontinued|category_name|         description|picture|\n",
      "+-----------+----------+--------------------+-----------+-------------------+----------+--------------+--------------+-------------+------------+-------------+--------------------+-------+\n",
      "|          1|         1|                Chai|          8| 10 boxes x 30 bags|      18.0|            39|             0|           10|           1|    Beverages|Soft drinks, coff...|     []|\n",
      "|          1|         2|               Chang|          1| 24 - 12 oz bottles|      19.0|            17|            40|           25|           1|    Beverages|Soft drinks, coff...|     []|\n",
      "|          2|         3|       Aniseed Syrup|          1|12 - 550 ml bottles|      10.0|            13|            70|           25|           0|   Condiments|Sweet and savory ...|     []|\n",
      "|          2|         4|Chef Anton's Caju...|          2|     48 - 6 oz jars|      22.0|            53|             0|            0|           0|   Condiments|Sweet and savory ...|     []|\n",
      "|          2|         5|Chef Anton's Gumb...|          2|           36 boxes|     21.35|             0|             0|            0|           1|   Condiments|Sweet and savory ...|     []|\n",
      "+-----------+----------+--------------------+-----------+-------------------+----------+--------------+--------------+-------------+------------+-------------+--------------------+-------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Broadcast join (pour petites tables)\n",
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "# La table categories est petite -> broadcast\n",
    "df_categories = spark.read.jdbc(url=jdbc_url, table=\"categories\", properties=jdbc_properties)\n",
    "\n",
    "df_joined = df_products.join(\n",
    "    broadcast(df_categories),\n",
    "    on=\"category_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_joined.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8938632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes : 2155\n",
      "CA total : 1354458.59\n"
     ]
    }
   ],
   "source": [
    "# Cache pour les DataFrames reutilises\n",
    "df_ventes_cached = df_ventes.cache()\n",
    "\n",
    "# Premiere utilisation (materialise le cache)\n",
    "print(f\"Nombre de lignes : {df_ventes_cached.count()}\")\n",
    "\n",
    "# Utilisations suivantes (depuis le cache)\n",
    "print(f\"CA total : {df_ventes_cached.agg(F.sum('montant')).collect()[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a886ac49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [category_id#22, product_id#19, product_name#20, supplier_id#21, quantity_per_unit#23, unit_price#24, units_in_stock#25, units_on_order#26, reorder_level#27, discontinued#28, category_name#1640, description#1641, picture#1642]\n",
      "   +- BroadcastHashJoin [category_id#22], [category_id#1639], LeftOuter, BuildRight, false\n",
      "      :- Scan JDBCRelation(products) [numPartitions=1] [product_id#19,product_name#20,supplier_id#21,category_id#22,quantity_per_unit#23,unit_price#24,units_in_stock#25,units_on_order#26,reorder_level#27,discontinued#28] PushedFilters: [], ReadSchema: struct<product_id:smallint,product_name:string,supplier_id:smallint,category_id:smallint,quantity...\n",
      "      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, smallint, true] as bigint)),false), [plan_id=3324]\n",
      "         +- Scan JDBCRelation(categories) [numPartitions=1] [category_id#1639,category_name#1640,description#1641,picture#1642] PushedFilters: [*IsNotNull(category_id)], ReadSchema: struct<category_id:smallint,category_name:string,description:string,picture:binary>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Voir le plan d'execution\n",
    "df_joined.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2388d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[order_id: smallint, product_id: smallint, unit_price: float, quantity: smallint, discount: float, order_date: date, montant: double, annee: int, mois: int]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liberer le cache\n",
    "df_ventes_cached.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bf4ed9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice\n",
    "\n",
    "**Objectif** : Creer une UDF et un pivot\n",
    "\n",
    "**Consigne** :\n",
    "1. Creez une UDF qui categorise les pays en regions (Europe, Amerique, Asie, Autre)\n",
    "2. Appliquez-la aux customers\n",
    "3. Faites un pivot des ventes par region et par trimestre\n",
    "\n",
    "A vous de jouer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbade88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Creer l'UDF de categorisation par region\n",
    "@udf(returnType=StringType())\n",
    "def categoriser_region(pays):\n",
    "    if pays is None:\n",
    "        return \"Inconnu\"\n",
    "        \n",
    "    # Listes des pays presents dans Northwind\n",
    "    europe = [\"UK\", \"France\", \"Germany\", \"Sweden\", \"Italy\", \"Spain\", \"Portugal\", \"Ireland\", \"Belgium\", \"Switzerland\", \"Austria\", \"Finland\", \"Poland\", \"Norway\", \"Denmark\"]\n",
    "    amerique = [\"USA\", \"Canada\", \"Brazil\", \"Mexico\", \"Argentina\", \"Venezuela\"]\n",
    "    asie = [\"Japan\", \"Singapore\", \"India\"]\n",
    "    \n",
    "    if pays in europe:\n",
    "        return \"Europe\"\n",
    "    elif pays in amerique:\n",
    "        return \"Amerique\"\n",
    "    elif pays in asie:\n",
    "        return \"Asie\"\n",
    "    else:\n",
    "        return \"Autre\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4b4e5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Chiffre d'Affaires par Région et Trimestre ===\n",
      "+------------+---------+---------+---------+---------+\n",
      "|region_monde|        1|        2|        3|        4|\n",
      "+------------+---------+---------+---------+---------+\n",
      "|    Amerique|194792.87|102882.88|110112.85| 119088.4|\n",
      "|      Europe|268329.15|203257.43|139504.29|216490.72|\n",
      "+------------+---------+---------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Appliquer aux customers et faire le pivot\n",
    "\n",
    "# Appliquer l'UDF pour ajouter la colonne 'region_monde'\n",
    "df_cust_region = df_customers.withColumn(\"region_monde\", categoriser_region(F.col(\"country\")))\n",
    "\n",
    "# Préparer la table des ventes complète (Jointures)\n",
    "df_ventes_complete = df_order_details.join(df_orders, on=\"order_id\") \\\n",
    "                                     .join(df_cust_region, on=\"customer_id\")\n",
    "\n",
    "# Ajouter les colonnes calculées (Montant et Trimestre)\n",
    "df_analyse = df_ventes_complete.withColumn(\n",
    "    \"montant\", \n",
    "    F.col(\"unit_price\") * F.col(\"quantity\")\n",
    ").withColumn(\n",
    "    \"trimestre\", \n",
    "    F.quarter(\"order_date\")\n",
    ")\n",
    "\n",
    "# Pivot : Région en lignes, Trimestres en colonnes\n",
    "df_pivot_region = df_analyse.groupBy(\"region_monde\") \\\n",
    "                            .pivot(\"trimestre\", [1, 2, 3, 4]) \\\n",
    "                            .agg(F.round(F.sum(\"montant\"), 2)) \\\n",
    "                            .fillna(0) \\\n",
    "                            .orderBy(\"region_monde\")\n",
    "\n",
    "print(\"=== Chiffre d'Affaires par Région et Trimestre ===\")\n",
    "df_pivot_region.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a784fb64",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Resume\n",
    "\n",
    "Dans ce notebook, vous avez appris :\n",
    "- Comment faire un **pivot** (lignes vers colonnes)\n",
    "- Comment creer des **UDF** Python et Pandas\n",
    "- Comment travailler avec les **arrays** et **maps**\n",
    "- Comment creer et utiliser des **structs**\n",
    "- Comment **optimiser** les performances (broadcast, cache)\n",
    "\n",
    "### Prochaine etape\n",
    "Dans le prochain notebook, nous approfondirons les jointures Spark."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
