{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8b328de",
   "metadata": {},
   "source": [
    "# Exercice 15 - Introduction a Kafka\n",
    "\n",
    "## Objectifs\n",
    "- Comprendre les concepts fondamentaux de Kafka\n",
    "- Decouvrir l'architecture Kafka\n",
    "- Creer des topics\n",
    "- Explorer l'interface Kafka UI\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9976e7dc",
   "metadata": {},
   "source": [
    "## 1. Qu'est-ce que Kafka ?\n",
    "\n",
    "**Apache Kafka** est une plateforme de streaming distribue.\n",
    "\n",
    "```\n",
    "+------------------------------------------------------------------+\n",
    "|                    ARCHITECTURE KAFKA                            |\n",
    "+------------------------------------------------------------------+\n",
    "|                                                                  |\n",
    "|   PRODUCTEURS           KAFKA BROKER           CONSOMMATEURS     |\n",
    "|                                                                  |\n",
    "|  +-----------+      +----------------+      +-----------+        |\n",
    "|  |           |      |                |      |           |        |\n",
    "|  | App Web   |----->|    TOPIC       |----->| Spark     |        |\n",
    "|  |           |      |    orders      |      |           |        |\n",
    "|  +-----------+      |                |      +-----------+        |\n",
    "|                     | +------------+ |                           |\n",
    "|  +-----------+      | | Partition 0| |      +-----------+        |\n",
    "|  |           |      | +------------+ |      |           |        |\n",
    "|  | IoT       |----->| | Partition 1| |----->| Analytics |        |\n",
    "|  | Devices   |      | +------------+ |      |           |        |\n",
    "|  +-----------+      | | Partition 2| |      +-----------+        |\n",
    "|                     | +------------+ |                           |\n",
    "|  +-----------+      |                |      +-----------+        |\n",
    "|  |           |      +----------------+      |           |        |\n",
    "|  | Script    |----->                  ----->| Dashboard |        |\n",
    "|  | Python    |                              |           |        |\n",
    "|  +-----------+                              +-----------+        |\n",
    "|                                                                  |\n",
    "+------------------------------------------------------------------+\n",
    "\n",
    "Concepts cles :\n",
    "- Topic     : categorie de messages (comme une table)\n",
    "- Partition : sous-division d'un topic (parallelisme)\n",
    "- Producer  : envoie des messages\n",
    "- Consumer  : recoit des messages\n",
    "- Broker    : serveur Kafka\n",
    "- Offset    : position d'un message dans une partition\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa88a66",
   "metadata": {},
   "source": [
    "## 2. Cas d'usage de Kafka\n",
    "\n",
    "```\n",
    "+------------------------------------------------------------------+\n",
    "|                    CAS D'USAGE KAFKA                             |\n",
    "+------------------------------------------------------------------+\n",
    "|                                                                  |\n",
    "|  1. STREAMING DE DONNEES                                         |\n",
    "|     - Logs en temps reel                                         |\n",
    "|     - Metriques systeme                                          |\n",
    "|     - Evenements utilisateur                                     |\n",
    "|                                                                  |\n",
    "|  2. INTEGRATION DE SYSTEMES                                      |\n",
    "|     - Synchronisation de bases                                   |\n",
    "|     - Communication microservices                                |\n",
    "|     - ETL en temps reel                                          |\n",
    "|                                                                  |\n",
    "|  3. EVENT SOURCING                                               |\n",
    "|     - Historique des evenements                                  |\n",
    "|     - Audit trail                                                |\n",
    "|     - Replay de donnees                                          |\n",
    "|                                                                  |\n",
    "|  4. ANALYTICS TEMPS REEL                                         |\n",
    "|     - Dashboards en direct                                       |\n",
    "|     - Alerting                                                   |\n",
    "|     - Detection d'anomalies                                      |\n",
    "|                                                                  |\n",
    "+------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8c27de",
   "metadata": {},
   "source": [
    "## 3. Notre infrastructure Kafka\n",
    "\n",
    "```\n",
    "+------------------------------------------------------------------+\n",
    "|                    NOTRE STACK                                   |\n",
    "+------------------------------------------------------------------+\n",
    "|                                                                  |\n",
    "|  +----------------+          +-------------------+               |\n",
    "|  |                |          |                   |               |\n",
    "|  |  Kafka Broker  |<-------->|    Kafka UI       |               |\n",
    "|  |  (port 9092)   |          |  (port 7080)      |               |\n",
    "|  |                |          |                   |               |\n",
    "|  +----------------+          +-------------------+               |\n",
    "|         |                                                        |\n",
    "|         |                                                        |\n",
    "|         v                                                        |\n",
    "|  +----------------+          +-------------------+               |\n",
    "|  |                |          |                   |               |\n",
    "|  | JupyterLab     |          |    Spark          |               |\n",
    "|  | (Producer)     |          |  (Consumer)       |               |\n",
    "|  |                |          |                   |               |\n",
    "|  +----------------+          +-------------------+               |\n",
    "|                                                                  |\n",
    "+------------------------------------------------------------------+\n",
    "\n",
    "URLs :\n",
    "- Kafka Broker : broker:9092 (interne Docker)\n",
    "- Kafka UI    : http://localhost:7080\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f8160",
   "metadata": {},
   "source": [
    "## 4. Installation de la bibliotheque Kafka Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0447576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kafka-python installe\n"
     ]
    }
   ],
   "source": [
    "# Installer kafka-python\n",
    "!pip install kafka-python -q\n",
    "\n",
    "print(\"kafka-python installe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d822329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Kafka : broker:9092\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaAdminClient, KafkaProducer, KafkaConsumer\n",
    "from kafka.admin import NewTopic\n",
    "\n",
    "# Configuration Kafka\n",
    "KAFKA_BROKER = \"broker:9092\"\n",
    "\n",
    "print(f\"Configuration Kafka : {KAFKA_BROKER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4097820e",
   "metadata": {},
   "source": [
    "## 5. Tester la connexion a Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e06363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de connexion : NodeNotReadyError: 1\n"
     ]
    }
   ],
   "source": [
    "# Tester la connexion\n",
    "try:\n",
    "    admin = KafkaAdminClient(\n",
    "        bootstrap_servers=KAFKA_BROKER,\n",
    "        client_id='test-connexion'\n",
    "    )\n",
    "    \n",
    "    # Lister les topics existants\n",
    "    topics = admin.list_topics()\n",
    "    print(\"Connexion Kafka OK\")\n",
    "    print(f\"Topics existants : {topics}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur de connexion : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe87fb",
   "metadata": {},
   "source": [
    "## 6. Creer un topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e274fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Tentative de connexion à Kafka...\n",
      "...............\n",
      "❌ Impossible de se connecter à Kafka après 60 secondes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from kafka import KafkaAdminClient\n",
    "from kafka.errors import NoBrokersAvailable, NodeNotReadyError\n",
    "\n",
    "KAFKA_BROKER = \"broker:9092\"\n",
    "\n",
    "def attendre_kafka(timeout=60):\n",
    "    print(\"⏳ Tentative de connexion à Kafka...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    while time.time() - start < timeout:\n",
    "        try:\n",
    "            # On tente juste de lister les topics pour voir si le broker répond\n",
    "            admin = KafkaAdminClient(bootstrap_servers=KAFKA_BROKER)\n",
    "            topics = admin.list_topics()\n",
    "            admin.close()\n",
    "            print(\"✅ Kafka est prêt !\")\n",
    "            return True\n",
    "        except (NoBrokersAvailable, NodeNotReadyError):\n",
    "            print(\".\", end=\"\", flush=True) # Affiche un point à chaque échec\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nErreur inattendue : {e}\")\n",
    "            time.sleep(2)\n",
    "            \n",
    "    print(\"\\n❌ Impossible de se connecter à Kafka après 60 secondes.\")\n",
    "    return False\n",
    "\n",
    "# Si Kafka est prêt, on lance la création\n",
    "if attendre_kafka():\n",
    "    # Votre fonction de création de topic\n",
    "    creer_topic(\"test-topic\", partitions=3)\n",
    "    creer_topic(\"commandes\", partitions=3)\n",
    "    creer_topic(\"logs\", partitions=1)\n",
    "    \n",
    "    # Vérification finale\n",
    "    print(\"\\nTopics existants :\")\n",
    "    admin = KafkaAdminClient(bootstrap_servers=KAFKA_BROKER)\n",
    "    print(admin.list_topics())\n",
    "    admin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f9f3fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur lors de la création du topic : NodeNotReadyError: 1\n",
      "Erreur lors de la création du topic : NodeNotReadyError: 1\n",
      "Erreur lors de la création du topic : NodeNotReadyError: 1\n"
     ]
    }
   ],
   "source": [
    "# Creer des topics pour nos exercices\n",
    "creer_topic(\"test-topic\", partitions=3)\n",
    "creer_topic(\"commandes\", partitions=3)\n",
    "creer_topic(\"logs\", partitions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a17bffe5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NodeNotReadyError",
     "evalue": "NodeNotReadyError: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNodeNotReadyError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Lister les topics\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m admin = \u001b[43mKafkaAdminClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbootstrap_servers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mKAFKA_BROKER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m topics = admin.list_topics()\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTopics Kafka :\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/kafka/admin/client.py:228\u001b[39m, in \u001b[36mKafkaAdminClient.__init__\u001b[39m\u001b[34m(self, **configs)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mapi_version\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m._client.config[\u001b[33m'\u001b[39m\u001b[33mapi_version\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    227\u001b[39m \u001b[38;5;28mself\u001b[39m._closed = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_refresh_controller_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    229\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mKafkaAdminClient started.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/kafka/admin/client.py:272\u001b[39m, in \u001b[36mKafkaAdminClient._refresh_controller_id\u001b[39m\u001b[34m(self, timeout_ms)\u001b[39m\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    271\u001b[39m \u001b[38;5;66;03m# verify the controller is new enough to support our requests\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m controller_version = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontroller_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m controller_version < (\u001b[32m0\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m0\u001b[39m):\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m IncompatibleBrokerVersion(\n\u001b[32m    275\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe controller appears to be running Kafka \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. KafkaAdminClient requires brokers >= 0.10.0.0.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    276\u001b[39m         .format(controller_version))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/kafka/client_async.py:1074\u001b[39m, in \u001b[36mKafkaClient.check_version\u001b[39m\u001b[34m(self, node_id, timeout, **kwargs)\u001b[39m\n\u001b[32m   1071\u001b[39m \u001b[38;5;66;03m# Timeout\u001b[39;00m\n\u001b[32m   1072\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1073\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m node_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1074\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Errors.NodeNotReadyError(node_id)\n\u001b[32m   1075\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1076\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Errors.NoBrokersAvailable()\n",
      "\u001b[31mNodeNotReadyError\u001b[39m: NodeNotReadyError: 1"
     ]
    }
   ],
   "source": [
    "# Lister les topics\n",
    "admin = KafkaAdminClient(bootstrap_servers=KAFKA_BROKER)\n",
    "topics = admin.list_topics()\n",
    "\n",
    "print(\"Topics Kafka :\")\n",
    "print(\"=\" * 30)\n",
    "for topic in sorted(topics):\n",
    "    if not topic.startswith(\"_\"):  # Ignorer les topics internes\n",
    "        print(f\"  - {topic}\")\n",
    "\n",
    "admin.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ace46",
   "metadata": {},
   "source": [
    "## 7. Envoyer des messages simples (Producer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c9f9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer un producer simple\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=KAFKA_BROKER,\n",
    "    value_serializer=lambda v: v.encode('utf-8')  # Encoder en bytes\n",
    ")\n",
    "\n",
    "print(\"Producer cree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Envoyer des messages\n",
    "for i in range(5):\n",
    "    message = f\"Message numero {i+1}\"\n",
    "    future = producer.send(\"test-topic\", value=message)\n",
    "    \n",
    "    # Attendre la confirmation\n",
    "    result = future.get(timeout=10)\n",
    "    print(f\"Envoye: {message} -> Partition {result.partition}, Offset {result.offset}\")\n",
    "\n",
    "producer.flush()  # S'assurer que tout est envoye\n",
    "print(\"\\nTous les messages envoyes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65d1ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fermer le producer\n",
    "producer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5170ebae",
   "metadata": {},
   "source": [
    "## 8. Lire des messages (Consumer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cd6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer un consumer\n",
    "consumer = KafkaConsumer(\n",
    "    \"test-topic\",\n",
    "    bootstrap_servers=KAFKA_BROKER,\n",
    "    auto_offset_reset='earliest',  # Lire depuis le debut\n",
    "    enable_auto_commit=True,\n",
    "    group_id='test-group',\n",
    "    value_deserializer=lambda v: v.decode('utf-8'),\n",
    "    consumer_timeout_ms=5000  # Timeout apres 5 secondes sans message\n",
    ")\n",
    "\n",
    "print(\"Consumer cree, lecture des messages...\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fdd5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire les messages\n",
    "messages_recus = 0\n",
    "\n",
    "for message in consumer:\n",
    "    print(f\"Topic: {message.topic}\")\n",
    "    print(f\"Partition: {message.partition}\")\n",
    "    print(f\"Offset: {message.offset}\")\n",
    "    print(f\"Valeur: {message.value}\")\n",
    "    print(\"-\" * 30)\n",
    "    messages_recus += 1\n",
    "\n",
    "print(f\"\\nTotal messages recus: {messages_recus}\")\n",
    "consumer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f95e3a4",
   "metadata": {},
   "source": [
    "## 9. Interface Kafka UI\n",
    "\n",
    "Kafka UI est accessible a l'adresse : **http://localhost:7080**\n",
    "\n",
    "```\n",
    "+------------------------------------------------------------------+\n",
    "|                    KAFKA UI                                      |\n",
    "+------------------------------------------------------------------+\n",
    "|                                                                  |\n",
    "|  Fonctionnalites :                                               |\n",
    "|                                                                  |\n",
    "|  1. TOPICS                                                       |\n",
    "|     - Liste des topics                                           |\n",
    "|     - Creation/suppression                                       |\n",
    "|     - Configuration                                              |\n",
    "|                                                                  |\n",
    "|  2. MESSAGES                                                     |\n",
    "|     - Visualisation des messages                                 |\n",
    "|     - Filtrage par offset                                        |\n",
    "|     - Envoi de messages                                          |\n",
    "|                                                                  |\n",
    "|  3. CONSUMERS                                                    |\n",
    "|     - Groupes de consommateurs                                   |\n",
    "|     - Lag (retard)                                               |\n",
    "|     - Reset offset                                               |\n",
    "|                                                                  |\n",
    "|  4. BROKERS                                                      |\n",
    "|     - Etat des brokers                                           |\n",
    "|     - Metriques                                                  |\n",
    "|                                                                  |\n",
    "+------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5397f9d3",
   "metadata": {},
   "source": [
    "## 10. Supprimer un topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6700b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supprimer_topic(nom_topic):\n",
    "    \"\"\"\n",
    "    Supprime un topic Kafka.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        admin = KafkaAdminClient(\n",
    "            bootstrap_servers=KAFKA_BROKER,\n",
    "            client_id='admin-delete'\n",
    "        )\n",
    "        \n",
    "        admin.delete_topics([nom_topic])\n",
    "        print(f\"Topic '{nom_topic}' supprime\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur : {e}\")\n",
    "    finally:\n",
    "        admin.close()\n",
    "\n",
    "# Exemple (commenté pour ne pas supprimer)\n",
    "# supprimer_topic(\"test-topic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a8756",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice\n",
    "\n",
    "**Objectif** : Experimenter avec Kafka\n",
    "\n",
    "**Consigne** :\n",
    "1. Creez un topic \"exercice-topic\" avec 2 partitions\n",
    "2. Envoyez 10 messages personnalises\n",
    "3. Lisez tous les messages\n",
    "4. Verifiez dans Kafka UI (http://localhost:7080)\n",
    "\n",
    "A vous de jouer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a1633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Creer le topic\n",
    "from kafka import KafkaAdminClient\n",
    "from kafka.admin import NewTopic\n",
    "\n",
    "KAFKA_BROKER = \"broker:9092\"\n",
    "\n",
    "def create_exo_topic():\n",
    "    admin = KafkaAdminClient(bootstrap_servers=KAFKA_BROKER)\n",
    "    try:\n",
    "        # Vérification pour ne pas créer de doublon\n",
    "        if \"exercice-topic\" not in admin.list_topics():\n",
    "            topic = NewTopic(name=\"exercice-topic\", num_partitions=2, replication_factor=1)\n",
    "            admin.create_topics([topic])\n",
    "            print(\"Topic 'exercice-topic' créé avec succès (2 partitions).\")\n",
    "        else:\n",
    "            print(\"Le topic 'exercice-topic' existe déjà.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur : {e}\")\n",
    "    finally:\n",
    "        admin.close()\n",
    "\n",
    "create_exo_topic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9b3e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Envoyer des messages\n",
    "from kafka import KafkaProducer\n",
    "import time\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=KAFKA_BROKER,\n",
    "    value_serializer=lambda v: v.encode('utf-8')\n",
    ")\n",
    "\n",
    "print(\"Début de l'envoi...\")\n",
    "\n",
    "for i in range(10):\n",
    "    msg = f\"Message Exercice #{i+1}\"\n",
    "    producer.send(\"exercice-topic\", value=msg)\n",
    "    print(f\"Envoi : {msg}\")\n",
    "    time.sleep(0.2)\n",
    "\n",
    "producer.flush() #pour forcer l'envoi des msg en mémoire\n",
    "producer.close()\n",
    "print(\"Tous les messages sont envoyés.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Lire les messages\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    \"exercice-topic\",\n",
    "    bootstrap_servers=KAFKA_BROKER,\n",
    "    auto_offset_reset='earliest',\n",
    "    enable_auto_commit=True,\n",
    "    group_id='groupe-exercice',\n",
    "    value_deserializer=lambda v: v.decode('utf-8'),\n",
    "    consumer_timeout_ms=5000\n",
    ")\n",
    "\n",
    "print(\"Lecture des messages du topic 'exercice-topic' :\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "msg_count = 0\n",
    "for msg in consumer:\n",
    "    # Affichage de la partition\n",
    "    print(f\"Partition {msg.partition} | Offset {msg.offset} | Contenu : {msg.value}\")\n",
    "    msg_count += 1\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Terminé. {msg_count} messages reçus.\")\n",
    "consumer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a231574a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Resume\n",
    "\n",
    "Dans ce notebook, vous avez appris :\n",
    "- Les **concepts fondamentaux** de Kafka (topic, partition, offset)\n",
    "- Les **cas d'usage** typiques\n",
    "- Comment **creer des topics**\n",
    "- Comment **envoyer des messages** (Producer)\n",
    "- Comment **lire des messages** (Consumer)\n",
    "- Comment utiliser **Kafka UI**\n",
    "\n",
    "### Prochaine etape\n",
    "Dans le prochain notebook, nous approfondirons la creation de Producer Kafka avec Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
