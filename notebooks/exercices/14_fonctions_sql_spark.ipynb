{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b3ef9da",
   "metadata": {},
   "source": [
    "# Exercice 14 - Fonctions SQL avec Spark\n",
    "\n",
    "## Objectifs\n",
    "- Utiliser Spark SQL pour interroger les DataFrames\n",
    "- Maitriser les fonctions SQL courantes\n",
    "- Combiner SQL et API DataFrame\n",
    "- Creer des vues temporaires et permanentes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effc05eb",
   "metadata": {},
   "source": [
    "## 1. Spark SQL\n",
    "\n",
    "```\n",
    "+------------------------------------------------------------------+\n",
    "|                         SPARK SQL                                |\n",
    "+------------------------------------------------------------------+\n",
    "|                                                                  |\n",
    "|  DataFrame     <------>    Vue SQL    <------>    Requete SQL    |\n",
    "|                                                                  |\n",
    "|  df_orders     ------>    orders      ------>    SELECT * FROM   |\n",
    "|                           (temp view)            orders          |\n",
    "|                                                                  |\n",
    "+------------------------------------------------------------------+\n",
    "|                                                                  |\n",
    "|  Avantages SQL :                                                 |\n",
    "|  - Syntaxe familiere                                             |\n",
    "|  - Requetes complexes lisibles                                   |\n",
    "|  - Meme optimiseur que DataFrame API                             |\n",
    "|                                                                  |\n",
    "+------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344246c5",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec7f006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark pret\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark SQL\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.6.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark pret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b8e1ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] orders : 830 lignes\n",
      "[OK] order_details : 2155 lignes\n",
      "[OK] products : 77 lignes\n",
      "[OK] customers : 91 lignes\n",
      "[OK] employees : 9 lignes\n",
      "[OK] categories : 8 lignes\n",
      "[OK] suppliers : 29 lignes\n",
      "\n",
      "Toutes les vues SQL creees\n"
     ]
    }
   ],
   "source": [
    "# Charger les donnees\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/app\"\n",
    "jdbc_properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "tables = [\"orders\", \"order_details\", \"products\", \"customers\", \"employees\", \"categories\", \"suppliers\"]\n",
    "\n",
    "for table in tables:\n",
    "    df = spark.read.jdbc(url=jdbc_url, table=table, properties=jdbc_properties)\n",
    "    df.createOrReplaceTempView(table)  # Creer une vue SQL\n",
    "    print(f\"[OK] {table} : {df.count()} lignes\")\n",
    "\n",
    "print(\"\\nToutes les vues SQL creees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c429bc",
   "metadata": {},
   "source": [
    "## 3. Requetes SQL de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3db826d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------+\n",
      "|customer_id|        company_name|country|\n",
      "+-----------+--------------------+-------+\n",
      "|      ALFKI| Alfreds Futterkiste|Germany|\n",
      "|      ANATR|Ana Trujillo Empa...| Mexico|\n",
      "|      ANTON|Antonio Moreno Ta...| Mexico|\n",
      "|      AROUT|     Around the Horn|     UK|\n",
      "|      BERGS|  Berglunds snabbköp| Sweden|\n",
      "|      BLAUS|Blauer See Delika...|Germany|\n",
      "|      BLONP|Blondesddsl père ...| France|\n",
      "|      BOLID|Bólido Comidas pr...|  Spain|\n",
      "|      BONAP|            Bon app'| France|\n",
      "|      BOTTM|Bottom-Dollar Mar...| Canada|\n",
      "+-----------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SELECT simple\n",
    "spark.sql(\"\"\"\n",
    "    SELECT customer_id, company_name, country\n",
    "    FROM customers\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63e0e267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|        product_name|unit_price|\n",
      "+--------------------+----------+\n",
      "|       Côte de Blaye|     263.5|\n",
      "|Thüringer Rostbra...|    123.79|\n",
      "|     Mishi Kobe Niku|      97.0|\n",
      "|Sir Rodney's Marm...|      81.0|\n",
      "|    Carnarvon Tigers|      62.5|\n",
      "|Raclette Courdavault|      55.0|\n",
      "|Manjimup Dried Ap...|      53.0|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# WHERE\n",
    "spark.sql(\"\"\"\n",
    "    SELECT product_name, unit_price\n",
    "    FROM products\n",
    "    WHERE unit_price > 50\n",
    "    ORDER BY unit_price DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101b0bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|    country|nb_clients|\n",
      "+-----------+----------+\n",
      "|        USA|        13|\n",
      "|    Germany|        11|\n",
      "|     France|        11|\n",
      "|     Brazil|         9|\n",
      "|         UK|         7|\n",
      "|      Spain|         5|\n",
      "|     Mexico|         5|\n",
      "|  Venezuela|         4|\n",
      "|  Argentina|         3|\n",
      "|      Italy|         3|\n",
      "|     Canada|         3|\n",
      "|     Sweden|         2|\n",
      "|    Belgium|         2|\n",
      "|    Finland|         2|\n",
      "|    Denmark|         2|\n",
      "|Switzerland|         2|\n",
      "|   Portugal|         2|\n",
      "|    Austria|         2|\n",
      "|     Norway|         1|\n",
      "|    Ireland|         1|\n",
      "+-----------+----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# GROUP BY\n",
    "spark.sql(\"\"\"\n",
    "    SELECT country, COUNT(*) as nb_clients\n",
    "    FROM customers\n",
    "    GROUP BY country\n",
    "    ORDER BY nb_clients DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a46beb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|country|nb_clients|\n",
      "+-------+----------+\n",
      "|    USA|        13|\n",
      "|Germany|        11|\n",
      "| France|        11|\n",
      "| Brazil|         9|\n",
      "|     UK|         7|\n",
      "|  Spain|         5|\n",
      "| Mexico|         5|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HAVING\n",
    "spark.sql(\"\"\"\n",
    "    SELECT country, COUNT(*) as nb_clients\n",
    "    FROM customers\n",
    "    GROUP BY country\n",
    "    HAVING COUNT(*) >= 5\n",
    "    ORDER BY nb_clients DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a2277",
   "metadata": {},
   "source": [
    "## 4. Jointures en SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "001b6497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------+-------+\n",
      "|order_id|order_date|  company_name|country|\n",
      "+--------+----------+--------------+-------+\n",
      "|   10374|1996-12-05|Wolski  Zajazd| Poland|\n",
      "|   10611|1997-07-25|Wolski  Zajazd| Poland|\n",
      "|   10792|1997-12-23|Wolski  Zajazd| Poland|\n",
      "|   10870|1998-02-04|Wolski  Zajazd| Poland|\n",
      "|   10906|1998-02-25|Wolski  Zajazd| Poland|\n",
      "|   10998|1998-04-03|Wolski  Zajazd| Poland|\n",
      "|   11044|1998-04-23|Wolski  Zajazd| Poland|\n",
      "|   10529|1997-05-07|  Maison Dewey|Belgium|\n",
      "|   10649|1997-08-28|  Maison Dewey|Belgium|\n",
      "|   10760|1997-12-01|  Maison Dewey|Belgium|\n",
      "+--------+----------+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# INNER JOIN\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        o.order_id,\n",
    "        o.order_date,\n",
    "        c.company_name,\n",
    "        c.country\n",
    "    FROM orders o\n",
    "    INNER JOIN customers c ON o.customer_id = c.customer_id\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57145c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+--------------------+-------------+--------+----------+\n",
      "|order_id|company_name     |product_name        |category_name|quantity|unit_price|\n",
      "+--------+-----------------+--------------------+-------------+--------+----------+\n",
      "|10623   |Frankenversand   |Guaraná Fantástica  |Beverages    |3       |4.5       |\n",
      "|10623   |Frankenversand   |Steeleye Stout      |Beverages    |30      |18.0      |\n",
      "|10817   |Königlich Essen  |Côte de Blaye       |Beverages    |30      |263.5     |\n",
      "|10703   |Folk och fä HB   |Chang               |Beverages    |5       |19.0      |\n",
      "|11025   |Wartian Herkku   |Chai                |Beverages    |10      |18.0      |\n",
      "|10468   |Königlich Essen  |Ipoh Coffee         |Beverages    |15      |36.8      |\n",
      "|10632   |Die Wandernde Kuh|Chang               |Beverages    |30      |19.0      |\n",
      "|10788   |QUICK-Stop       |Rhönbräu Klosterbier|Beverages    |40      |7.75      |\n",
      "|10840   |LINO-Delicateses |Chartreuse verte    |Beverages    |10      |18.0      |\n",
      "|10257   |HILARION-Abastos |Chartreuse verte    |Beverages    |6       |14.4      |\n",
      "+--------+-----------------+--------------------+-------------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Jointure multiple\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        o.order_id,\n",
    "        c.company_name,\n",
    "        p.product_name,\n",
    "        cat.category_name,\n",
    "        od.quantity,\n",
    "        od.unit_price\n",
    "    FROM order_details od\n",
    "    JOIN orders o ON od.order_id = o.order_id\n",
    "    JOIN customers c ON o.customer_id = c.customer_id\n",
    "    JOIN products p ON od.product_id = p.product_id\n",
    "    JOIN categories cat ON p.category_id = cat.category_id\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea0ea408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------------+\n",
      "|customer_id|        company_name|nb_commandes|\n",
      "+-----------+--------------------+------------+\n",
      "|      PARIS|   Paris spécialités|           0|\n",
      "|      FISSA|FISSA Fabrica Int...|           0|\n",
      "|      CENTC|Centro comercial ...|           1|\n",
      "|      GROSR|GROSELLA-Restaurante|           2|\n",
      "|      LAZYK|Lazy K Kountry Store|           2|\n",
      "|      CONSH|Consolidated Hold...|           3|\n",
      "|      TRAIH|Trail's Head Gour...|           3|\n",
      "|      FRANR| France restauration|           3|\n",
      "|      BOLID|Bólido Comidas pr...|           3|\n",
      "|      THECR|     The Cracker Box|           3|\n",
      "+-----------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LEFT JOIN avec condition\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        c.customer_id,\n",
    "        c.company_name,\n",
    "        COUNT(o.order_id) as nb_commandes\n",
    "    FROM customers c\n",
    "    LEFT JOIN orders o ON c.customer_id = o.customer_id\n",
    "    GROUP BY c.customer_id, c.company_name\n",
    "    ORDER BY nb_commandes\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378f5a6e",
   "metadata": {},
   "source": [
    "## 5. Fonctions de date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5b899f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----+----+----+---------+------------+-------+\n",
      "|order_id|order_date|annee|mois|jour|trimestre|jour_semaine|semaine|\n",
      "+--------+----------+-----+----+----+---------+------------+-------+\n",
      "|   10248|1996-07-04| 1996|   7|   4|        3|           5|     27|\n",
      "|   10249|1996-07-05| 1996|   7|   5|        3|           6|     27|\n",
      "|   10250|1996-07-08| 1996|   7|   8|        3|           2|     28|\n",
      "|   10251|1996-07-08| 1996|   7|   8|        3|           2|     28|\n",
      "|   10252|1996-07-09| 1996|   7|   9|        3|           3|     28|\n",
      "+--------+----------+-----+----+----+---------+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extraction de composants de date\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        order_date,\n",
    "        YEAR(order_date) as annee,\n",
    "        MONTH(order_date) as mois,\n",
    "        DAY(order_date) as jour,\n",
    "        QUARTER(order_date) as trimestre,\n",
    "        DAYOFWEEK(order_date) as jour_semaine,\n",
    "        WEEKOFYEAR(order_date) as semaine\n",
    "    FROM orders\n",
    "    LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c82bfd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------+-----------+\n",
      "|order_id|order_date|shipped_date|delai_jours|\n",
      "+--------+----------+------------+-----------+\n",
      "|   10248|1996-07-04|  1996-07-16|         12|\n",
      "|   10249|1996-07-05|  1996-07-10|          5|\n",
      "|   10250|1996-07-08|  1996-07-12|          4|\n",
      "|   10251|1996-07-08|  1996-07-15|          7|\n",
      "|   10252|1996-07-09|  1996-07-11|          2|\n",
      "|   10253|1996-07-10|  1996-07-16|          6|\n",
      "|   10254|1996-07-11|  1996-07-23|         12|\n",
      "|   10255|1996-07-12|  1996-07-15|          3|\n",
      "|   10256|1996-07-15|  1996-07-17|          2|\n",
      "|   10257|1996-07-16|  1996-07-22|          6|\n",
      "+--------+----------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcul de differences de dates\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        order_date,\n",
    "        shipped_date,\n",
    "        DATEDIFF(shipped_date, order_date) as delai_jours\n",
    "    FROM orders\n",
    "    WHERE shipped_date IS NOT NULL\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3e53559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----------+--------+\n",
      "|order_id|order_date|date_fr   |mois_annee|nom_jour|\n",
      "+--------+----------+----------+----------+--------+\n",
      "|10248   |1996-07-04|04/07/1996|July 1996 |Thursday|\n",
      "|10249   |1996-07-05|05/07/1996|July 1996 |Friday  |\n",
      "|10250   |1996-07-08|08/07/1996|July 1996 |Monday  |\n",
      "|10251   |1996-07-08|08/07/1996|July 1996 |Monday  |\n",
      "|10252   |1996-07-09|09/07/1996|July 1996 |Tuesday |\n",
      "+--------+----------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Formatage de dates\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        order_date,\n",
    "        DATE_FORMAT(order_date, 'dd/MM/yyyy') as date_fr,\n",
    "        DATE_FORMAT(order_date, 'MMMM yyyy') as mois_annee,\n",
    "        DATE_FORMAT(order_date, 'EEEE') as nom_jour\n",
    "    FROM orders\n",
    "    LIMIT 5\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6850dd4a",
   "metadata": {},
   "source": [
    "## 6. Fonctions de chaines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64649385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+----------------------------------+----------------------------------+--------+----------+\n",
      "|company_name                      |upper_name                        |lower_name                        |longueur|debut     |\n",
      "+----------------------------------+----------------------------------+----------------------------------+--------+----------+\n",
      "|Alfreds Futterkiste               |ALFREDS FUTTERKISTE               |alfreds futterkiste               |19      |Alfreds Fu|\n",
      "|Ana Trujillo Emparedados y helados|ANA TRUJILLO EMPAREDADOS Y HELADOS|ana trujillo emparedados y helados|34      |Ana Trujil|\n",
      "|Antonio Moreno Taquería           |ANTONIO MORENO TAQUERÍA           |antonio moreno taquería           |23      |Antonio Mo|\n",
      "|Around the Horn                   |AROUND THE HORN                   |around the horn                   |15      |Around the|\n",
      "|Berglunds snabbköp                |BERGLUNDS SNABBKÖP                |berglunds snabbköp                |18      |Berglunds |\n",
      "+----------------------------------+----------------------------------+----------------------------------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Manipulation de chaines\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        company_name,\n",
    "        UPPER(company_name) as upper_name,\n",
    "        LOWER(company_name) as lower_name,\n",
    "        LENGTH(company_name) as longueur,\n",
    "        SUBSTRING(company_name, 1, 10) as debut\n",
    "    FROM customers\n",
    "    LIMIT 5\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35d087de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------------+-----------------+\n",
      "|first_name|last_name|       full_name|       nom_formel|\n",
      "+----------+---------+----------------+-----------------+\n",
      "|     Nancy|  Davolio|   Nancy Davolio|   Davolio, Nancy|\n",
      "|    Andrew|   Fuller|   Andrew Fuller|   Fuller, Andrew|\n",
      "|     Janet|Leverling| Janet Leverling| Leverling, Janet|\n",
      "|  Margaret|  Peacock|Margaret Peacock|Peacock, Margaret|\n",
      "|    Steven| Buchanan| Steven Buchanan| Buchanan, Steven|\n",
      "|   Michael|   Suyama|  Michael Suyama|  Suyama, Michael|\n",
      "|    Robert|     King|     Robert King|     King, Robert|\n",
      "|     Laura| Callahan|  Laura Callahan|  Callahan, Laura|\n",
      "|      Anne|Dodsworth|  Anne Dodsworth|  Dodsworth, Anne|\n",
      "+----------+---------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Concatenation et remplacement\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        first_name,\n",
    "        last_name,\n",
    "        CONCAT(first_name, ' ', last_name) as full_name,\n",
    "        CONCAT_WS(', ', last_name, first_name) as nom_formel\n",
    "    FROM employees\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46c79573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|product_name                    |\n",
      "+--------------------------------+\n",
      "|Aniseed Syrup                   |\n",
      "|Northwoods Cranberry Sauce      |\n",
      "|Louisiana Fiery Hot Pepper Sauce|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recherche et pattern matching\n",
    "spark.sql(\"\"\"\n",
    "    SELECT product_name\n",
    "    FROM products\n",
    "    WHERE product_name LIKE '%Sauce%'\n",
    "       OR product_name LIKE '%Syrup%'\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce86a6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|product_name                |\n",
      "+----------------------------+\n",
      "|Chai                        |\n",
      "|Chang                       |\n",
      "|Aniseed Syrup               |\n",
      "|Chef Anton's Cajun Seasoning|\n",
      "|Chef Anton's Gumbo Mix      |\n",
      "|Alice Mutton                |\n",
      "|Carnarvon Tigers            |\n",
      "|Côte de Blaye               |\n",
      "|Chartreuse verte            |\n",
      "|Boston Crab Meat            |\n",
      "|Chocolade                   |\n",
      "|Camembert Pierrot           |\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Expression reguliere\n",
    "spark.sql(\"\"\"\n",
    "    SELECT product_name\n",
    "    FROM products\n",
    "    WHERE product_name RLIKE '^[A-C]'\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964bd708",
   "metadata": {},
   "source": [
    "## 7. Fonctions d'agregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6198ddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------+--------+-----------+\n",
      "|nb_produits|prix_moyen|prix_min|prix_max|stock_total|\n",
      "+-----------+----------+--------+--------+-----------+\n",
      "|         77|     28.83|     2.5|   263.5|       3119|\n",
      "+-----------+----------+--------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agregations de base\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as nb_produits,\n",
    "        ROUND(AVG(unit_price), 2) as prix_moyen,\n",
    "        MIN(unit_price) as prix_min,\n",
    "        MAX(unit_price) as prix_max,\n",
    "        ROUND(SUM(units_in_stock), 0) as stock_total\n",
    "    FROM products\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4591f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+----------+-----------+\n",
      "| category_name|nb_produits|prix_moyen|stock_total|\n",
      "+--------------+-----------+----------+-----------+\n",
      "|   Confections|         13|     25.16|        386|\n",
      "|    Condiments|         12|     22.85|        507|\n",
      "|     Beverages|         12|     37.98|        559|\n",
      "|       Seafood|         12|     20.68|        701|\n",
      "|Dairy Products|         10|     28.73|        393|\n",
      "|Grains/Cereals|          7|     20.25|        308|\n",
      "|  Meat/Poultry|          6|     54.01|        165|\n",
      "|       Produce|          5|     32.37|        100|\n",
      "+--------------+-----------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agregation avec GROUP BY\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        cat.category_name,\n",
    "        COUNT(*) as nb_produits,\n",
    "        ROUND(AVG(p.unit_price), 2) as prix_moyen,\n",
    "        SUM(p.units_in_stock) as stock_total\n",
    "    FROM products p\n",
    "    JOIN categories cat ON p.category_id = cat.category_id\n",
    "    GROUP BY cat.category_name\n",
    "    ORDER BY nb_produits DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0338c3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+------------------+---------------+--------------+\n",
      "| category_name|total_produits|produits_pas_chers|produits_moyens|produits_chers|\n",
      "+--------------+--------------+------------------+---------------+--------------+\n",
      "|Dairy Products|            10|                 2|              7|             1|\n",
      "|  Meat/Poultry|             6|                 1|              3|             2|\n",
      "|    Condiments|            12|                 5|              7|             0|\n",
      "|     Beverages|            12|                10|              1|             1|\n",
      "|Grains/Cereals|             7|                 4|              3|             0|\n",
      "|       Seafood|            12|                 8|              3|             1|\n",
      "|   Confections|            13|                 8|              4|             1|\n",
      "|       Produce|             5|                 1|              3|             1|\n",
      "+--------------+--------------+------------------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agregation conditionnelle\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        category_name,\n",
    "        COUNT(*) as total_produits,\n",
    "        SUM(CASE WHEN unit_price < 20 THEN 1 ELSE 0 END) as produits_pas_chers,\n",
    "        SUM(CASE WHEN unit_price >= 20 AND unit_price < 50 THEN 1 ELSE 0 END) as produits_moyens,\n",
    "        SUM(CASE WHEN unit_price >= 50 THEN 1 ELSE 0 END) as produits_chers\n",
    "    FROM products p\n",
    "    JOIN categories c ON p.category_id = c.category_id\n",
    "    GROUP BY category_name\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f740a1",
   "metadata": {},
   "source": [
    "## 8. Sous-requetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bf63cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|        product_name|unit_price|\n",
      "+--------------------+----------+\n",
      "|       Côte de Blaye|     263.5|\n",
      "|Thüringer Rostbra...|    123.79|\n",
      "|     Mishi Kobe Niku|      97.0|\n",
      "|Sir Rodney's Marm...|      81.0|\n",
      "|    Carnarvon Tigers|      62.5|\n",
      "|Raclette Courdavault|      55.0|\n",
      "|Manjimup Dried Ap...|      53.0|\n",
      "|      Tarte au sucre|      49.3|\n",
      "|         Ipoh Coffee|      46.0|\n",
      "|   Rössle Sauerkraut|      45.6|\n",
      "|  Schoggi Schokolade|      43.9|\n",
      "|        Vegie-spread|      43.9|\n",
      "|Northwoods Cranbe...|      40.0|\n",
      "|        Alice Mutton|      39.0|\n",
      "|Queso Manchego La...|      38.0|\n",
      "|Gnocchi di nonna ...|      38.0|\n",
      "|    Gudbrandsdalsost|      36.0|\n",
      "|Mozzarella di Gio...|      34.8|\n",
      "|   Camembert Pierrot|      34.0|\n",
      "|Wimmers gute Semm...|     33.25|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Sous-requete dans WHERE\n",
    "spark.sql(\"\"\"\n",
    "    SELECT product_name, unit_price\n",
    "    FROM products\n",
    "    WHERE unit_price > (\n",
    "        SELECT AVG(unit_price) FROM products\n",
    "    )\n",
    "    ORDER BY unit_price DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58f4f881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|        company_name|  country|\n",
      "+--------------------+---------+\n",
      "|      Wolski  Zajazd|   Poland|\n",
      "|        Maison Dewey|  Belgium|\n",
      "|Blauer See Delika...|  Germany|\n",
      "|Magazzini Aliment...|    Italy|\n",
      "|      Folk och fä HB|   Sweden|\n",
      "|Ana Trujillo Empa...|   Mexico|\n",
      "|      Island Trading|       UK|\n",
      "|        Vaffeljernet|  Denmark|\n",
      "|Blondesddsl père ...|   France|\n",
      "|Split Rail Beer &...|      USA|\n",
      "|Trail's Head Gour...|      USA|\n",
      "|   LILA-Supermercado|Venezuela|\n",
      "|      Wartian Herkku|  Finland|\n",
      "| France restauration|   France|\n",
      "|  Seven Seas Imports|       UK|\n",
      "|  Eastern Connection|       UK|\n",
      "|    HILARION-Abastos|Venezuela|\n",
      "|       Hanari Carnes|   Brazil|\n",
      "|Drachenblut Delik...|  Germany|\n",
      "|Vins et alcools C...|   France|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Sous-requete avec IN\n",
    "spark.sql(\"\"\"\n",
    "    SELECT company_name, country\n",
    "    FROM customers\n",
    "    WHERE customer_id IN (\n",
    "        SELECT DISTINCT customer_id\n",
    "        FROM orders\n",
    "        WHERE order_date >= '1997-01-01'\n",
    "    )\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca042ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|company_name      |\n",
      "+------------------+\n",
      "|Save-a-lot Markets|\n",
      "|Ernst Handel      |\n",
      "|QUICK-Stop        |\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sous-requete avec EXISTS\n",
    "spark.sql(\"\"\"\n",
    "    SELECT c.company_name\n",
    "    FROM customers c\n",
    "    WHERE EXISTS (\n",
    "        SELECT 1\n",
    "        FROM orders o\n",
    "        JOIN order_details od ON o.order_id = od.order_id\n",
    "        WHERE o.customer_id = c.customer_id\n",
    "        AND od.quantity >= 100\n",
    "    )\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bed4233",
   "metadata": {},
   "source": [
    "## 9. Common Table Expressions (CTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55108332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------------------+------------------+\n",
      "|customer_id|company_name                |ca_total          |\n",
      "+-----------+----------------------------+------------------+\n",
      "|QUICK      |QUICK-Stop                  |117483.390147686  |\n",
      "|SAVEA      |Save-a-lot Markets          |115673.38964271545|\n",
      "|ERNSH      |Ernst Handel                |113236.67978191376|\n",
      "|HUNGO      |Hungry Owl All-Night Grocers|57317.39016246796 |\n",
      "|RATTC      |Rattlesnake Canyon Grocery  |52245.90034675598 |\n",
      "|HANAR      |Hanari Carnes               |34101.149973869324|\n",
      "|FOLKO      |Folk och fä HB              |32555.55001926422 |\n",
      "|MEREP      |Mère Paillarde              |32203.900234222412|\n",
      "|KOENE      |Königlich Essen             |31745.749893188477|\n",
      "|QUEEN      |Queen Cozinha               |30226.10017967224 |\n",
      "+-----------+----------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CTE simple\n",
    "spark.sql(\"\"\"\n",
    "    WITH ventes_client AS (\n",
    "        SELECT \n",
    "            c.customer_id,\n",
    "            c.company_name,\n",
    "            SUM(od.unit_price * od.quantity) as ca_total\n",
    "        FROM customers c\n",
    "        JOIN orders o ON c.customer_id = o.customer_id\n",
    "        JOIN order_details od ON o.order_id = od.order_id\n",
    "        GROUP BY c.customer_id, c.company_name\n",
    "    )\n",
    "    SELECT *\n",
    "    FROM ventes_client\n",
    "    WHERE ca_total > 30000\n",
    "    ORDER BY ca_total DESC\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86b3d585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---------+--------+-----------+\n",
      "|annee|mois|       ca|ca_moyen|performance|\n",
      "+-----+----+---------+--------+-----------+\n",
      "| 1996|   7|  30192.1| 58889.5| En dessous|\n",
      "| 1996|   8|  26609.4| 58889.5| En dessous|\n",
      "| 1996|   9|  27636.0| 58889.5| En dessous|\n",
      "| 1996|  10|  41203.6| 58889.5| En dessous|\n",
      "| 1996|  11|  49704.0| 58889.5| En dessous|\n",
      "| 1996|  12|  50953.4| 58889.5| En dessous|\n",
      "| 1997|   1|  66692.8| 58889.5|  Au dessus|\n",
      "| 1997|   2|  41207.2| 58889.5| En dessous|\n",
      "| 1997|   3|  39979.9| 58889.5| En dessous|\n",
      "| 1997|   4| 55699.39| 58889.5| En dessous|\n",
      "| 1997|   5|  56823.7| 58889.5| En dessous|\n",
      "| 1997|   6|  39088.0| 58889.5| En dessous|\n",
      "| 1997|   7| 55464.93| 58889.5| En dessous|\n",
      "| 1997|   8| 49981.69| 58889.5| En dessous|\n",
      "| 1997|   9| 59733.02| 58889.5|  Au dessus|\n",
      "| 1997|  10|  70328.5| 58889.5|  Au dessus|\n",
      "| 1997|  11| 45913.36| 58889.5| En dessous|\n",
      "| 1997|  12| 77476.26| 58889.5|  Au dessus|\n",
      "| 1998|   1|100854.72| 58889.5|  Au dessus|\n",
      "| 1998|   2|104561.95| 58889.5|  Au dessus|\n",
      "+-----+----+---------+--------+-----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# CTE multiples\n",
    "spark.sql(\"\"\"\n",
    "    WITH \n",
    "    ventes_mensuelles AS (\n",
    "        SELECT \n",
    "            YEAR(order_date) as annee,\n",
    "            MONTH(order_date) as mois,\n",
    "            SUM(od.unit_price * od.quantity) as ca\n",
    "        FROM orders o\n",
    "        JOIN order_details od ON o.order_id = od.order_id\n",
    "        GROUP BY YEAR(order_date), MONTH(order_date)\n",
    "    ),\n",
    "    moyenne AS (\n",
    "        SELECT AVG(ca) as ca_moyen\n",
    "        FROM ventes_mensuelles\n",
    "    )\n",
    "    SELECT \n",
    "        v.annee,\n",
    "        v.mois,\n",
    "        ROUND(v.ca, 2) as ca,\n",
    "        ROUND(m.ca_moyen, 2) as ca_moyen,\n",
    "        CASE \n",
    "            WHEN v.ca > m.ca_moyen THEN 'Au dessus'\n",
    "            ELSE 'En dessous'\n",
    "        END as performance\n",
    "    FROM ventes_mensuelles v\n",
    "    CROSS JOIN moyenne m\n",
    "    ORDER BY v.annee, v.mois\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c1fecd",
   "metadata": {},
   "source": [
    "## 10. Fonctions de fenetre (Window Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e6089c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+----------+-------+----+----------+\n",
      "|category_name|        product_name|unit_price|row_num|rang|dense_rang|\n",
      "+-------------+--------------------+----------+-------+----+----------+\n",
      "|    Beverages|       Côte de Blaye|     263.5|      1|   1|         1|\n",
      "|    Beverages|         Ipoh Coffee|      46.0|      2|   2|         2|\n",
      "|    Beverages|               Chang|      19.0|      3|   3|         3|\n",
      "|    Beverages|                Chai|      18.0|      4|   4|         4|\n",
      "|    Beverages|      Steeleye Stout|      18.0|      5|   4|         4|\n",
      "|    Beverages|    Chartreuse verte|      18.0|      6|   4|         4|\n",
      "|    Beverages|        Lakkalikööri|      18.0|      7|   4|         4|\n",
      "|    Beverages|       Outback Lager|      15.0|      8|   8|         5|\n",
      "|    Beverages|       Sasquatch Ale|      14.0|      9|   9|         6|\n",
      "|    Beverages|Laughing Lumberja...|      14.0|     10|   9|         6|\n",
      "|    Beverages|Rhönbräu Klosterbier|      7.75|     11|  11|         7|\n",
      "|    Beverages|  Guaraná Fantástica|       4.5|     12|  12|         8|\n",
      "|   Condiments|        Vegie-spread|      43.9|      1|   1|         1|\n",
      "|   Condiments|Northwoods Cranbe...|      40.0|      2|   2|         2|\n",
      "|   Condiments|      Sirop d'érable|      28.5|      3|   3|         3|\n",
      "|   Condiments|Grandma's Boysenb...|      25.0|      4|   4|         4|\n",
      "|   Condiments|Chef Anton's Caju...|      22.0|      5|   5|         5|\n",
      "|   Condiments|Chef Anton's Gumb...|     21.35|      6|   6|         6|\n",
      "|   Condiments|Louisiana Fiery H...|     21.05|      7|   7|         7|\n",
      "|   Condiments|        Gula Malacca|     19.45|      8|   8|         8|\n",
      "+-------------+--------------------+----------+-------+----+----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# ROW_NUMBER, RANK, DENSE_RANK\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        category_name,\n",
    "        product_name,\n",
    "        unit_price,\n",
    "        ROW_NUMBER() OVER (PARTITION BY category_name ORDER BY unit_price DESC) as row_num,\n",
    "        RANK() OVER (PARTITION BY category_name ORDER BY unit_price DESC) as rang,\n",
    "        DENSE_RANK() OVER (PARTITION BY category_name ORDER BY unit_price DESC) as dense_rang\n",
    "    FROM products p\n",
    "    JOIN categories c ON p.category_id = c.category_id\n",
    "\"\"\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e0a350a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+------------+----------+-------------+\n",
      "|               mois|ca_actuel|ca_precedent|ca_suivant|evolution_pct|\n",
      "+-------------------+---------+------------+----------+-------------+\n",
      "|1996-07-01 00:00:00|  30192.1|        NULL|   26609.4|         NULL|\n",
      "|1996-08-01 00:00:00|  26609.4|     30192.1|   27636.0|       -11.87|\n",
      "|1996-09-01 00:00:00|  27636.0|     26609.4|   41203.6|         3.86|\n",
      "|1996-10-01 00:00:00|  41203.6|     27636.0|   49704.0|        49.09|\n",
      "|1996-11-01 00:00:00|  49704.0|     41203.6|   50953.4|        20.63|\n",
      "|1996-12-01 00:00:00|  50953.4|     49704.0|   66692.8|         2.51|\n",
      "|1997-01-01 00:00:00|  66692.8|     50953.4|   41207.2|        30.89|\n",
      "|1997-02-01 00:00:00|  41207.2|     66692.8|   39979.9|       -38.21|\n",
      "|1997-03-01 00:00:00|  39979.9|     41207.2|  55699.39|        -2.98|\n",
      "|1997-04-01 00:00:00| 55699.39|     39979.9|   56823.7|        39.32|\n",
      "|1997-05-01 00:00:00|  56823.7|    55699.39|   39088.0|         2.02|\n",
      "|1997-06-01 00:00:00|  39088.0|     56823.7|  55464.93|       -31.21|\n",
      "|1997-07-01 00:00:00| 55464.93|     39088.0|  49981.69|         41.9|\n",
      "|1997-08-01 00:00:00| 49981.69|    55464.93|  59733.02|        -9.89|\n",
      "|1997-09-01 00:00:00| 59733.02|    49981.69|   70328.5|        19.51|\n",
      "|1997-10-01 00:00:00|  70328.5|    59733.02|  45913.36|        17.74|\n",
      "|1997-11-01 00:00:00| 45913.36|     70328.5|  77476.26|       -34.72|\n",
      "|1997-12-01 00:00:00| 77476.26|    45913.36| 100854.72|        68.74|\n",
      "|1998-01-01 00:00:00|100854.72|    77476.26| 104561.95|        30.17|\n",
      "|1998-02-01 00:00:00|104561.95|   100854.72| 109825.45|         3.68|\n",
      "+-------------------+---------+------------+----------+-------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# LAG et LEAD\n",
    "spark.sql(\"\"\"\n",
    "    WITH ventes_mois AS (\n",
    "        SELECT \n",
    "            DATE_TRUNC('month', order_date) as mois,\n",
    "            SUM(od.unit_price * od.quantity) as ca\n",
    "        FROM orders o\n",
    "        JOIN order_details od ON o.order_id = od.order_id\n",
    "        GROUP BY DATE_TRUNC('month', order_date)\n",
    "    )\n",
    "    SELECT \n",
    "        mois,\n",
    "        ROUND(ca, 2) as ca_actuel,\n",
    "        ROUND(LAG(ca, 1) OVER (ORDER BY mois), 2) as ca_precedent,\n",
    "        ROUND(LEAD(ca, 1) OVER (ORDER BY mois), 2) as ca_suivant,\n",
    "        ROUND((ca - LAG(ca, 1) OVER (ORDER BY mois)) / LAG(ca, 1) OVER (ORDER BY mois) * 100, 2) as evolution_pct\n",
    "    FROM ventes_mois\n",
    "    ORDER BY mois\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04d03ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---------+----------+\n",
      "|order_date|    ca|ca_cumule|moyenne_7j|\n",
      "+----------+------+---------+----------+\n",
      "|1996-07-04| 440.0|    440.0|     440.0|\n",
      "|1996-07-05|1863.4|   2303.4|    1151.7|\n",
      "|1996-07-08|2483.8|   4787.2|   1595.73|\n",
      "|1996-07-09|3730.0|   8517.2|    2129.3|\n",
      "|1996-07-10|1444.8|   9962.0|    1992.4|\n",
      "|1996-07-11| 625.2|  10587.2|   1764.53|\n",
      "|1996-07-12|2490.5|  13077.7|   1868.24|\n",
      "|1996-07-15| 517.8|  13595.5|   1879.36|\n",
      "|1996-07-16|1119.9|  14715.4|   1773.14|\n",
      "|1996-07-17|2018.6|  16734.0|   1706.69|\n",
      "|1996-07-18| 100.8|  16834.8|   1188.23|\n",
      "|1996-07-19|2194.2|  19029.0|   1295.29|\n",
      "|1996-07-22| 624.8|  19653.8|   1295.23|\n",
      "|1996-07-23|2464.8|  22118.6|   1291.56|\n",
      "|1996-07-24| 724.5|  22843.1|   1321.09|\n",
      "|1996-07-25|1176.0|  24019.1|    1329.1|\n",
      "|1996-07-26| 364.8|  24383.9|   1092.84|\n",
      "|1996-07-29|4031.0|  28414.9|    1654.3|\n",
      "|1996-07-30|1101.2|  29516.1|   1498.16|\n",
      "|1996-07-31| 676.0|  30192.1|   1505.47|\n",
      "+----------+------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cumul et moyenne mobile\n",
    "spark.sql(\"\"\"\n",
    "    WITH ventes_jour AS (\n",
    "        SELECT \n",
    "            order_date,\n",
    "            SUM(od.unit_price * od.quantity) as ca\n",
    "        FROM orders o\n",
    "        JOIN order_details od ON o.order_id = od.order_id\n",
    "        GROUP BY order_date\n",
    "    )\n",
    "    SELECT \n",
    "        order_date,\n",
    "        ROUND(ca, 2) as ca,\n",
    "        ROUND(SUM(ca) OVER (ORDER BY order_date), 2) as ca_cumule,\n",
    "        ROUND(AVG(ca) OVER (ORDER BY order_date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW), 2) as moyenne_7j\n",
    "    FROM ventes_jour\n",
    "    ORDER BY order_date\n",
    "    LIMIT 20\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7949b00",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice\n",
    "\n",
    "**Objectif** : Ecrire des requetes SQL complexes\n",
    "\n",
    "**Consigne** :\n",
    "1. Trouvez le top 3 des produits par categorie (en termes de CA)\n",
    "2. Calculez le CA mensuel avec le cumul annuel\n",
    "3. Trouvez les clients qui ont commande plus que la moyenne\n",
    "\n",
    "A vous de jouer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eef1a3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------------+------------------+----+\n",
      "|category_name |product_name                    |ca_total          |rang|\n",
      "+--------------+--------------------------------+------------------+----+\n",
      "|Beverages     |Côte de Blaye                   |149984.20082092285|1   |\n",
      "|Beverages     |Ipoh Coffee                     |25079.199867248535|2   |\n",
      "|Beverages     |Chang                           |18559.19992351532 |3   |\n",
      "|Condiments    |Vegie-spread                    |17696.30004119873 |1   |\n",
      "|Condiments    |Sirop d'érable                  |16438.79990005493 |2   |\n",
      "|Condiments    |Louisiana Fiery Hot Pepper Sauce|14606.999431610107|3   |\n",
      "|Confections   |Tarte au sucre                  |49827.89999771118 |1   |\n",
      "|Confections   |Sir Rodney's Marmalade          |23635.800323486328|2   |\n",
      "|Confections   |Gumbär Gummibärchen             |21534.89967918396 |3   |\n",
      "|Dairy Products|Raclette Courdavault            |76296.0           |1   |\n",
      "|Dairy Products|Camembert Pierrot               |50286.00037384033 |2   |\n",
      "|Dairy Products|Mozzarella di Giovanni          |25738.7993850708  |3   |\n",
      "|Grains/Cereals|Gnocchi di nonna Alice          |45121.19985580444 |1   |\n",
      "|Grains/Cereals|Wimmers gute Semmelknödel       |23009.000091552734|2   |\n",
      "|Grains/Cereals|Singaporean Hokkien Fried Mee   |9332.399975776672 |3   |\n",
      "|Meat/Poultry  |Thüringer Rostbratwurst         |87736.40051269531 |1   |\n",
      "|Meat/Poultry  |Alice Mutton                    |35482.20026016235 |2   |\n",
      "|Meat/Poultry  |Perth Pasties                   |21510.199951171875|3   |\n",
      "|Produce       |Manjimup Dried Apples           |44742.60031890869 |1   |\n",
      "|Produce       |Rössle Sauerkraut               |26865.59979248047 |2   |\n",
      "+--------------+--------------------------------+------------------+----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# TODO: Top 3 produits par categorie\n",
    "spark.sql(\"\"\"\n",
    "    WITH ventes_produit AS (\n",
    "        SELECT \n",
    "            c.category_name,\n",
    "            p.product_name,\n",
    "            SUM(od.unit_price * od.quantity) as ca_total\n",
    "        FROM order_details od\n",
    "        JOIN products p ON od.product_id = p.product_id\n",
    "        JOIN categories c ON p.category_id = c.category_id\n",
    "        GROUP BY c.category_name, p.product_name\n",
    "    ),\n",
    "    classement AS (\n",
    "        SELECT \n",
    "            *,\n",
    "            RANK() OVER (PARTITION BY category_name ORDER BY ca_total DESC) as rang\n",
    "        FROM ventes_produit\n",
    "    )\n",
    "    SELECT * FROM classement \n",
    "    WHERE rang <= 3\n",
    "    ORDER BY category_name, rang\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9be92702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------------+\n",
      "|annee|mois|ca_mensuel|cumul_annuel|\n",
      "+-----+----+----------+------------+\n",
      "| 1996|   7|   30192.1|     30192.1|\n",
      "| 1996|   8|   26609.4|     56801.5|\n",
      "| 1996|   9|   27636.0|     84437.5|\n",
      "| 1996|  10|   41203.6|    125641.1|\n",
      "| 1996|  11|   49704.0|    175345.1|\n",
      "| 1996|  12|   50953.4|    226298.5|\n",
      "| 1997|   1|   66692.8|     66692.8|\n",
      "| 1997|   2|   41207.2|    107900.0|\n",
      "| 1997|   3|   39979.9|    147879.9|\n",
      "| 1997|   4|  55699.39|   203579.29|\n",
      "| 1997|   5|   56823.7|   260402.99|\n",
      "| 1997|   6|   39088.0|   299490.99|\n",
      "| 1997|   7|  55464.93|   354955.92|\n",
      "| 1997|   8|  49981.69|   404937.61|\n",
      "| 1997|   9|  59733.02|   464670.63|\n",
      "| 1997|  10|   70328.5|   534999.13|\n",
      "| 1997|  11|  45913.36|   580912.49|\n",
      "| 1997|  12|  77476.26|   658388.75|\n",
      "| 1998|   1| 100854.72|   100854.72|\n",
      "| 1998|   2| 104561.95|   205416.67|\n",
      "+-----+----+----------+------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# TODO: CA mensuel avec cumul annuel\n",
    "spark.sql(\"\"\"\n",
    "    WITH ventes_mois AS (\n",
    "        SELECT \n",
    "            YEAR(o.order_date) as annee,\n",
    "            MONTH(o.order_date) as mois,\n",
    "            SUM(od.unit_price * od.quantity) as ca_mois\n",
    "        FROM orders o\n",
    "        JOIN order_details od ON o.order_id = od.order_id\n",
    "        GROUP BY YEAR(o.order_date), MONTH(o.order_date)\n",
    "    )\n",
    "    SELECT \n",
    "        annee,\n",
    "        mois,\n",
    "        ROUND(ca_mois, 2) as ca_mensuel,\n",
    "        ROUND(SUM(ca_mois) OVER (PARTITION BY annee ORDER BY mois), 2) as cumul_annuel\n",
    "    FROM ventes_mois\n",
    "    ORDER BY annee, mois\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bf34a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------+----------------+\n",
      "|company_name                |ca_client|moyenne_generale|\n",
      "+----------------------------+---------+----------------+\n",
      "|QUICK-Stop                  |117483.39|15218.64        |\n",
      "|Save-a-lot Markets          |115673.39|15218.64        |\n",
      "|Ernst Handel                |113236.68|15218.64        |\n",
      "|Hungry Owl All-Night Grocers|57317.39 |15218.64        |\n",
      "|Rattlesnake Canyon Grocery  |52245.9  |15218.64        |\n",
      "|Hanari Carnes               |34101.15 |15218.64        |\n",
      "|Folk och fä HB              |32555.55 |15218.64        |\n",
      "|Mère Paillarde              |32203.9  |15218.64        |\n",
      "|Königlich Essen             |31745.75 |15218.64        |\n",
      "|Queen Cozinha               |30226.1  |15218.64        |\n",
      "|White Clover Markets        |29073.45 |15218.64        |\n",
      "|Frankenversand              |28722.71 |15218.64        |\n",
      "|Berglunds snabbköp          |26968.15 |15218.64        |\n",
      "|Piccolo und mehr            |26259.95 |15218.64        |\n",
      "|Suprêmes délices            |24704.4  |15218.64        |\n",
      "|Bon app'                    |23850.95 |15218.64        |\n",
      "|HILARION-Abastos            |23611.58 |15218.64        |\n",
      "|Bottom-Dollar Markets       |22607.7  |15218.64        |\n",
      "|Lehmanns Marktstand         |21282.02 |15218.64        |\n",
      "|Richter Supermarkt          |20033.2  |15218.64        |\n",
      "+----------------------------+---------+----------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# TODO: Clients au dessus de la moyenne\n",
    "spark.sql(\"\"\"\n",
    "    WITH ventes_clients AS (\n",
    "        SELECT \n",
    "            c.company_name,\n",
    "            SUM(od.unit_price * od.quantity) as total_achats\n",
    "        FROM customers c\n",
    "        JOIN orders o ON c.customer_id = o.customer_id\n",
    "        JOIN order_details od ON o.order_id = od.order_id\n",
    "        GROUP BY c.company_name\n",
    "    ),\n",
    "    moyenne_globale AS (\n",
    "        SELECT AVG(total_achats) as moyenne FROM ventes_clients\n",
    "    )\n",
    "    SELECT \n",
    "        v.company_name,\n",
    "        ROUND(v.total_achats, 2) as ca_client,\n",
    "        ROUND(m.moyenne, 2) as moyenne_generale\n",
    "    FROM ventes_clients v\n",
    "    CROSS JOIN moyenne_globale m\n",
    "    WHERE v.total_achats > m.moyenne\n",
    "    ORDER BY v.total_achats DESC\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a9c236",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Resume\n",
    "\n",
    "Dans ce notebook, vous avez appris :\n",
    "- Comment utiliser **Spark SQL** avec des vues temporaires\n",
    "- Les **fonctions de date** (YEAR, MONTH, DATEDIFF, DATE_FORMAT)\n",
    "- Les **fonctions de chaines** (CONCAT, UPPER, LIKE, RLIKE)\n",
    "- Les **fonctions d'agregation** (SUM, AVG, COUNT, CASE)\n",
    "- Les **sous-requetes** et **CTE**\n",
    "- Les **fonctions de fenetre** (ROW_NUMBER, LAG, LEAD, cumul)\n",
    "\n",
    "### Prochaine etape\n",
    "Dans le prochain notebook, nous apprendrons les bases de Kafka."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
